## AWS SAP
https://d1.awsstatic.com/ja_JP/training-and-certification/docs-sa-pro/AWS-Certified-Solutions-Architect-Professional_Exam-Guide.pdf

### 問題を解くポイント
- 1問あたり2分半（190分/75問=2.5333）
- 翻訳は雑であることを意識する。要件に合う〜のところで、未来形なのに現在進行形かのように書いてあるなど。
- 選択肢をヒントにしながら問題文を読む。問題文はヘビーで読むのが疲れる。
- 消去法で選ぶことになる。一発で選べることはない。
- 問題のパターンは以下4つ。どれに当てはまるかを考えると、問題文が読みやすくなる。
  - 複雑な組織向け
  - 新しい要件を満たす
  - 既存の要件を見直す
  - オンプレからAWSクラウドへの移行
- 180分と長丁場で、意外と時間もないので、なるべく早く問題文を理解して2択まで絞り、最後に2択で悩むことに集中を注ぐようにする。
- ダークモードにする

## 一問一答

<details>
<summary>MQTTプロトコルとは？</summary>

- MQTT（Message Queuing Telemetry Transport）は、軽量・低消費電力・非同期な双方向通信が可能な通信プロトコル。
- 帯域やリソースが限られる IoT 向けに設計されており、HTTP より軽量。
- AWS では、IoT Core で収集 → Firehose → Flink で分析 → S3 保存、という構成が典型例。

</details>

<details>
<summary>MQTTプロトコルを処理するためのAWSサービスは何があり、どう使い分ける？</summary>

- MQTTを扱えるAWSサービスは主に AWS IoT Core と Amazon MQ の2つ。
- AWS IoT Core は、IoTデバイス向けに特化したフルマネージドの MQTT ブローカーで、大量デバイス接続、証明書認証、AWSサービスとの連携までを前提に設計されています。IoTデータをAWSに集約・処理したい場合の標準選択です。
- Amazon MQ は、ActiveMQ／RabbitMQ ベースの汎用メッセージブローカーで、MQTTにも対応します。既存のMQTTやメッセージング基盤を、そのままAWSへ移行したい場合に向いています。
- 要するに、IoT用途なら AWS IoT Core、既存システム移行なら Amazon MQです。

</details>

<details>
<summary>Kinesis Data Streams と Amazon Managed Service for Apache Flink は何が違う？</summary>

- Kinesis Data Streams は、アプリやデバイスから送られてくる大量のイベントデータを、順序を保ったまま安定して受信・保持・配信するためのストリーミング基盤です。主な役割は「止めずに流し続けること」で、処理ロジックは基本的に持ちません。一方、Amazon Managed Service for Apache Flink は、その Data Streams を流れているデータをリアルタイムに読み取り、集計・変換・フィルタリング・状態管理といった高度な処理を行うためのストリーム処理エンジンです。つまり、Data Streams はデータの通り道、Flink はその流れを理解して判断・加工する頭脳という関係になります。
- 前の名前の方がわかりやすい気がする
  - Amazon Kinesis Data Analytics　⇒　Amazon Managed Service for Apache Flink

</details>

<details>
<summary>Kinesis Data Streams と Amazon Managed Streaming for Apache Kafka（MSK） の違いは？</summary>

- Kinesis Data Streams と Amazon Managed Streaming for Apache Kafka（MSK） の違いは、「AWSネイティブで簡単に使いたいか」「Kafka互換を前提にしたいか」です。
- Kinesis Data Streams は、AWS 独自のフルマネージドなストリーミング基盤です。シャードという概念でスケールし、AWS SDK だけで簡単に使えます。運用は最小限で済み、Lambda や Firehose、Flink など AWS サービスとの統合が非常に強いのが特徴です。新規にストリーム処理を始める場合や、AWS完結でシンプルに構築したい場合に向いています。
- Amazon MSK は、Apache Kafka を AWS がマネージドで提供するサービスです。Kafka の API やエコシステム（Kafka Streams、Kafka Connect、既存ツール）をそのまま使えますが、ブローカー構成やキャパシティ設計など、Kinesis に比べると運用要素は多めです。既に Kafka を使っている、または Kafka 互換が必須な場合に選びます。

</details>

<details>
<summary>Auto Scaling のスケールイン時に EC2 のログを失わないためには、どのような仕組みを設計すればよいか？</summary>

- Auto Scaling のライフサイクルフックを使って EC2 の終了処理を一時停止し、終了イベントを Amazon EventBridge で検知する。EventBridge をトリガーに AWS Lambda を起動し、Lambda から AWS Systems Manager の SendCommand を呼び出して、SSM ドキュメントに定義したコマンドを EC2 上で実行する。これにより、EC2 内のログファイルを Amazon S3 にコピーした後、ライフサイクルフックに CONTINUE を送信してインスタンスを安全に終了させる。
- なぜ Lambda から直接 EC2 に SSH せず、SSM を使うのか？
  - SSH 接続にはネットワーク設定や鍵管理が必要になるが、SSM を使えば IAM による権限制御だけで EC2 にコマンドを実行できるためである。これにより、運用負荷とセキュリティリスクを大きく下げられる。

</details>

<details>
<summary>Splunkとは？</summary>

- Splunk（スプランク）とは、AWSエンジニア目線で言うと「CloudWatch Logs を超強化して、AWS外も含めて横断分析できるログ分析基盤」です。
- CloudWatch が「AWSリソースの状態監視・アラート」が主目的なのに対し、Splunk は ログを軸にシステム全体を横断的に検索・相関分析し、原因を深掘りするためのツールです。EC2 や ALB のログだけでなく、オンプレミス、ネットワーク機器、SaaS のログまで同じ検索言語で扱えます。
- AWS 構成に置き換えると、
  - CloudWatch：リアルタイム監視・アラート
  - Splunk：障害調査・セキュリティ分析（SIEM）・横断ログ分析
- 一言で言えば、Splunk は「AWSの中も外もまとめて、ログから“なぜ起きたか”を解くための分析基盤」です。

</details>

<details>
<summary>SQSのmacReceiveCountを1より大きくするとは？</summary>

- SQS の maxReceiveCount を 1 より大きくするとは、メッセージ処理に失敗した場合、すぐに DLQ に送らず、何度か再処理を許可する設定です。
- maxReceiveCount = 1 はリトライなし、maxReceiveCount > 1 は一時的な失敗を吸収するためのリトライあり、という意味になります。

</details>

<details>
<summary>EC2 Auto Scalingのスケールイン保護とは？</summary>

- EC2 Auto Scaling のスケールイン保護とは、Auto Scaling によるスケールイン（インスタンス削除）の対象から、特定の EC2 インスタンスを除外する機能です。
- これを有効にすると、そのインスタンスは スケールインが発生しても自動終了されません。
- バッチ処理の実行中や、セッションを保持しているインスタンスなど、途中で落としたくないインスタンスを守るために使います。

</details>

<details>
<summary>EMR のクラスタとは何か？</summary>

- EMR のクラスタとは、Apache Spark や Hadoop などの分散処理フレームワークを実行するために構成された、複数の EC2 インスタンスの集合体です。単一のサーバーで処理できない大量データを、役割分担された複数ノードで並列処理するための実行環境を指します。

</details>

<details>
<summary>EMR のノードにはどのようなタイプがある？なぜ分けている？</summary>

- プライマリノード、コアノード、タスクノードの 3 種類
- クラスタ管理、データ保存、実際の計算処理を分離することで、処理の安定性と拡張性を高めるためです。役割を分けることで、管理機能を安定させつつ、処理性能だけを柔軟にスケールできます。
  - プライマリノードはクラスタの司令塔であり、ジョブのスケジューリング、リソース管理、ノードの状態監視などを行います。通常は 1 台構成で、ここが停止するとクラスタ全体の処理に影響が出ます。

</details>

<details>
<summary>✅ Application Discovery Service のデータは可視化以外にどのような活用ができるか？</summary>

- 収集したデータは 2 通りの方法で分析に活用できる。
  - 1 つは AWS Migration Hub から Amazon S3 にエクスポートし、Amazon Athena を使って SQL によるバッチ分析を行う方法。
  - もう 1 つは Kinesis Data Firehose を利用して S3 に継続的に配信し、Athena で時系列・継続的な分析を行う方法である。

</details>

<details>
<summary>7Rとは？</summary>

- Rehost、Relocate、Replatform、Repurchase、Refactor、Retire、Retain
- https://zenn.dev/kasa/articles/aws-migration

</details>

<details>
<summary>S3 selectとは？</summary>

- お気軽Athena
- 単一ファイルのみ実施可能(複数ファイルは不可)
- https://qiita.com/miyuki_samitani/items/288540bf6ebf4b9eeac1

</details>

<details>
<summary>AWS Application Migration Service（AWS MGN）とは？</summary>

- オンプレミスや他クラウドで動いている VM を、最小限のダウンタイムで EC2 に移行するための AWS の移行サービスです。
- VMware 環境では、vCenter Client で管理されている VM（仮想マシン） が移行対象になります。各 VM に MGN のエージェントをインストールすると、VM のディスク変更が継続的に AWS にレプリケーションされます。カットオーバー時には、そのデータを使って EC2 インスタンスが自動作成されます。
- ポイント
  - VM（仮想マシン）単位で移行できる
  - vCenter Client で管理している既存 VMware 環境を前提に使える
- OS やアプリをほぼ変更せずに移行（Rehost）できる
- 一言でまとめると、MGN は「vCenter で管理されている VM を、そのまま EC2 に引っ越すための公式リフト＆シフトサービス」です。

</details>

<details>
<summary>VMware、vSphere、vCenter を AWS に置き換えると、それぞれ何に相当するか？</summary>

- VMware＝AWS
- vSphere＝EC2 基盤
- vCenter＝AWS マネジメントコンソール

</details>

<details>
<summary>IAM の動的ポリシーとは何か？</summary>

- IAM の動的ポリシーとは、ポリシーの Condition を利用して、アクセス元 IP、時刻、MFA の有無、タグなどの 実行時の条件 によってアクセス可否を判断する IAM ポリシーの考え方である。あらかじめ固定された許可ではなく、リクエスト時の状況に応じて権限が変わる点が特徴で、「動的ポリシー」という専用サービスがあるわけではない。

</details>

<details>
<summary>IAM Identity Center の許可セットは、通常の IAM ポリシーと何が違うのか？</summary>

- 通常の IAM ポリシーは 1つの AWS アカウント内の IAM ユーザーやロールに直接付与する権限定義であり、アカウントごとに作成・管理する必要があります。
- 一方、IAM Identity Center の許可セットは、複数の AWS アカウントにまたがって使い回せる権限のひな形で、ユーザーやグループに割り当てると、指定した各アカウントに同等の権限が自動的に反映されます。
- そのため、権限管理を Identity Center に集約でき、「どのアカウントにどの権限を与えているか」を一元的に把握しやすくなる点が大きな違いです。

</details>

<details>
<summary>IAM Access Analyzer とは何か？</summary>

- IAM Access Analyzer とは、IAM ポリシーやリソースポリシーを静的に解析し、AWS アカウント外（他アカウントやインターネット）からアクセス可能になっているリソースを検出するサービスである。
- 実際のアクセス履歴を確認するのではなく、「意図せず外部に公開されている設定」が存在しないかを見つけ出すことを目的としている。

</details>

<details>
<summary>パイロットライトとウォームスタンバイの違い</summary>

- パイロットライト：最低限のデータベースやストレージのみを仕様してデータを複製しておく
- ウォームスタンバイ：パイロットライトに加えて、最小限のロジック層を起動しておく

</details>

<details>
<summary>EC2 インスタンスの メモリ使用量をもとに、適切な EC2 インスタンスタイプを選定したい。</summary>

- EC2 インスタンスに CloudWatch Agent をインストールしてメモリ使用量を CloudWatch に送信し、その実測データを基に AWS Compute Optimizer を有効化して、インスタンスタイプの最適化提案を取得する。
- CloudWatch Agent によってメモリ使用率などの詳細な利用状況を収集し、Compute Optimizer がそれらの実績データを分析することで、インスタンスが過剰か不足しているかを判断できる。これにより、性能劣化を防ぎつつコストを最適化した EC2 インスタンスタイプを選定できる。

</details>

<details>
<summary>Compute Optimizer は何をしてくれるサービスか？</summary>

- Compute Optimizer は、EC2、EBS、Lambda などの AWS リソースについて、CloudWatch に蓄積された実際の利用メトリクス（CPU、メモリ、ネットワーク、ディスク I/O など）を継続的に分析し、性能とコストの観点から最適な構成を提案するサービスである。
- インスタンスが過剰に大きい場合や、逆にリソース不足で性能劣化のリスクがある場合を判定し、変更候補となるインスタンスタイプやサイズ、想定されるコスト削減効果やパフォーマンス影響を具体的に提示する。
- なお、提案は自動適用されるわけではなく、利用者が判断して変更を行うための意思決定支援を目的としたサービスである。
- Compute Optimizer 自体の利用料金は 無料。

</details>

<details>
<summary>Billing and Cost Management と Cost Explorer の違いは？</summary>

- 「請求・支払い・設定」 → Billing and Cost Management
- 「どこでいくら使ったか分析」 → Cost Explorer

</details>

<details>
<summary>Trusted Advisor と Compute Optimizer の正しい使い分けは？</summary>

- 全体的な無駄やリスクを広く洗い出したい場合は Trusted Advisor、EC2 のサイズやタイプを具体的に最適化したい場合は Compute Optimizer を使用する。
- Trusted Advisor：広く浅く「気づかせる」
- Compute Optimizer：狭く深く「どう変えるか教える」

</details>

<details>
<summary>試験で Trusted Advisor が正解になるのはどんなときか？</summary>

- 「ベストプラクティスチェック」「無駄なリソースの洗い出し」「セキュリティや制限の確認」といった抽象度の高い改善が求められている場合である。

</details>

<details>
<summary>試験で Compute Optimizer が正解になるキーワードは？</summary>

- 「適切なインスタンスタイプ」「サイズ最適化」「メモリ使用量」「コスト削減効果の提示」といった具体的な最適化が問われている場合。

</details>

<details>
<summary>手動で作成済みの AWS リソースを、削除や再作成をせずに CloudFormation 管理に移行したい。どうするべきか？</summary>

- CloudFormation の 既存リソースインポート を使用する。
- 既存リソースを新規作成せず、CloudFormation スタックの管理下に取り込むことができる。
- スタックは新しく作成されるが、リソース自体はそのまま利用される。
- すべての AWS リソースがインポートに対応しているわけではなく、対応リソースは一部に限られる。
- 手動構築された既存環境でも、後から CloudFormation による IaC 管理へ段階的に移行できる点が特徴である。

</details>

<details>
<summary>API Gateway のリージョンエンドポイントは、エッジロケーションを使うという意味か？</summary>

- 使わない。
- リージョンエンドポイントは、指定した AWS リージョン内に存在する API Gateway に直接アクセスする方式であり、エッジロケーションは利用しない。
- エッジロケーション（CloudFront）を自動的に利用するのは、エッジ最適化（Edge-Optimized）エンドポイントである。

</details>

<details>
<summary>API Gateway のエッジ最適化（Edge-Optimized）エンドポイントとは？</summary>

- API Gateway の前段に CloudFront が自動的に配置され、クライアントは最寄りのエッジロケーションにアクセスするエンドポイントである。
- リクエストはエッジロケーションから API Gateway が存在するリージョンへ転送され、グローバルユーザーからのアクセス時のレイテンシ低減を目的としている。
- CloudFront を個別に構築する必要はなく、API Gateway 側でエッジ最適化を選択するだけで利用できる。

</details>

<details>
<summary>UltraWarm ノードとは？</summary>

- UltraWarm ノードは、検索頻度は下がったが、まだ検索可能な状態で保持したいデータを保存するためのノードである。
- データは S3 上に保存され、必要に応じてキャッシュされるため、ホットノードより低コストで大量データを保持できる。
- 主に過去ログや長期間参照される分析データに使用される。

</details>

<details>
<summary>どんなときに CAPABILITY_NAMED_IAM が必要になる？</summary>

CloudFormation テンプレート内で、次のように IAM リソースの名前を固定で指定している場合に必要となる。

- IAM ロールに RoleName を指定している
- IAM ユーザーに UserName を指定している
- IAM ポリシーに PolicyName を指定している

名前を指定せず、CloudFormation に自動生成させる場合は不要である。

</details>

<details>
<summary>Service Catalog が向いている利用シーンは？</summary>

- 開発者や部門ごとにインフラを起動させたい
- ただし構成は標準化したい
- 中央チームでテンプレートを管理したい
- 複数アカウントへ同じインフラを配布したい

このような「ガバナンス付きセルフサービス」に向いている。

</details>

<details>
<summary>Service Catalog と AWS Marketplace の決定的な違いは？</summary>

- Service Catalog
  - 自社内向けに、承認済みインフラをセルフサービス提供する仕組み
- AWS Marketplace
  - 他社または自社のソフトウェアを、サービスとして提供・購入できる仕組み
- 「社内ガバナンス」か「サービス提供・販売」かが違う。

</details>

<details>
<summary>Lambda SnapStart とは？</summary>

AWS Lambda のコールドスタート時間を大幅に短縮するための機能である。

関数の初期化処理が完了した状態をスナップショットとして保存し、次回以降の起動時にその状態を復元することで、起動時間を高速化する。

</details>

<details>
<summary>Lambdaにおいて、なぜ一意な ID 生成はハンドラーの内側に書くべきか？</summary>

- ハンドラーの外側で生成すると、初期化時に作られた値が使い回されてしまうためである。
- 特に Lambda SnapStart を使用すると、初期化時の状態がスナップショットとして固定され、すべての実行で同じ値が使われてしまう。
- リクエストごとに異なる値を生成する処理や、毎回実行すべきロジックはハンドラー内に記述する。

</details>

<details>
<summary>✅ なぜ「EC2 Image Builder」はインスタンスタイプ制御の問題では不正解になりやすいのか？</summary>

- EC2 Image Builder は、AMI（ゴールデンイメージ）を作成・管理するためのサービスである。
- 目的は、OS やミドルウェア、アプリケーションの構成を標準化し、セキュリティパッチ適用や構成の再現性を高めることにある。
- Image Builder でできるのは「インスタンスの中身」を揃えることであり、「どのインスタンスタイプで起動できるか」を制御することはできない。
- そのため、Image Builder を使っても、t3.small でも m6i.32xlarge でも同じ AMI から起動できてしまう。
- つまりこれは、
  - 「何を載せるか」の話であり
  - 「どのサイズで起動させるか」の話ではない
- インスタンスタイプを制限したいという要件には、EC2 Image Builder は適さない。

</details>

<details>
<summary>✅ 開発者に標準化された OS・ミドルウェア構成を使わせたい。どのサービスが適切か？</summary>

EC2 Image Builder。

EC2 Image Builder は、AMI（ゴールデンイメージ）を自動的に作成・更新するためのサービスであり、OS やミドルウェア、パッチ適用状態を統一したい場合に適している。

</details>

<details>
<summary>✅ 開発者が起動できる EC2 のインスタンスタイプそのものを制限したい。どの仕組みを使うべきか？</summary>

IAM ポリシー。

IAM ポリシーの条件キー（ec2:InstanceType）を使用することで、特定のインスタンスタイプ以外の起動を API レベルで拒否できる。

</details>

<details>
<summary>NFS から Amazon EFS にデータ転送するにあたって、AWS DataSync を使用し、Direct Connect（Private VIF）を利用する場合、どのような接続方式を選択すべきか？</summary>

- AWS DataSync は、オンプレミスに配置したエージェントが AWS のマネージドサービスを経由して EFS にデータを転送する仕組みである。
- Direct Connect の Private VIF では VPC 内リソースにしか到達できないため、AWS マネージドサービスとプライベートに通信するための接続方式を使用する必要がある。
- そのため、Interface VPC Endpoint を用いた接続方式を選択する。

</details>

<details>
<summary>DocumentDB と DynamoDB のスケーリングの考え方の違いは？</summary>

- DocumentDB はマネージドデータベースではあるが、クラスタのインスタンスサイズや台数といった構成は利用者が設計・調整する必要がある。
- 負荷の増加に応じて、インスタンスのスケールアップやレプリカの追加を判断・実施する運用が前提となる。
- 一方、DynamoDB はオンデマンドキャパシティを利用することで、事前のキャパシティ設計や調整を意識せずに利用できる。
- トラフィックの増減に応じて自動的にスケールするため、運用負荷が大幅に低い。

</details>

<details>
<summary>なぜ DynamoDB は「プライベートサブネットのみ」の要件と相性が良いのか？</summary>

- DynamoDB は AWS マネージドサービスであり、Gateway VPC Endpoint を利用することで VPC 内からプライベートにアクセスできる。
- この構成では、インターネットゲートウェイや NAT ゲートウェイを経由する必要がなく、トラフィックは AWS ネットワーク内で完結する。

</details>

<details>
<summary>タグエディタで付けたタグは、そのままコスト配分タグとして使えるか？</summary>

- 使えるが、別途有効化が必要である。
- タグエディタでタグを付与しただけではコスト配分タグとしては機能せず、Billing and Cost Management で該当タグを「コスト配分タグ」として有効化する必要がある。

</details>

<details>
<summary>Interface VPC Endpoint とは何を作る仕組みか？</summary>

VPC 内に ENI（Elastic Network Interface）を作成し、AWS のパブリックサービスへプライベート IP で接続するための入口を用意する仕組みである。

通信経路は用意されるが、DNS 設定は別途考慮が必要である。

</details>

<details>
<summary>Interface VPC Endpoint を利用して AWS パブリックサービスへプライベート接続したい。DNS 周りでどのような対応を取るべきか？</summary>

- VPC の Private DNS オプションを有効にする。
- Interface VPC Endpoint では、AWS があらかじめサービス標準ドメインに対応する DNS レコードを用意しており、Private DNS を有効にすることで、その名前解決先が自動的にエンドポイントのプライベート IP に切り替わる。
- そのため、Route 53 のプライベートホストゾーンを新たに作成したり、独自に DNS レコードを管理したりする必要はない。

</details>

<details>
<summary>Amazon EBS を ECS タスクへマウントできるか？</summary>

- できるが、条件がある。
- Amazon EBS を ECS タスクにマウントできるのは、ECS の起動タイプが EC2 の場合に限られる。
- EBS は EC2 インスタンスにアタッチされるブロックストレージであり、ECS on EC2 では、その EC2 にアタッチした EBS をタスクから利用できる。

</details>

<details>
<summary>Fargate 起動タイプの ECS タスクで Amazon EBS をマウントできるか？</summary>

- できない。
- Fargate では基盤となる EC2 インスタンスを利用者が管理しないため、EBS を直接アタッチして利用することはできない。
- Fargate で永続ストレージが必要な場合は、Amazon EFS を使用する。

</details>


<details>
<summary>✅ リソースのタグ付を強制させたい場合は？</summary>

- タグポリシーとSCPを併用する
- SCP だけでも不十分！　SCP は「許可／拒否」を強制できますが、「どんなタグが正しいか」「値の候補や表記ゆれ」までは表現できません。
- SCP 単体だと「必須タグはあるが、値がバラバラ」「プロジェクト名が free text 地獄」になりがちです。

</details>

<details>
<summary>VPC ピアリングとPrivateLinkが選択肢に出た時に意識すること</summary>

- 通信方向が双方向か一方向か

</details>

<details>
<summary>組織全体のリソース共有するには？</summary>

- TransitGatewayではないよ！
- Organizationsで受け入れ許可 + Resource Access Manager（RAM）

</details>

<details>
<summary>✅ 移行にあたって最も費用対効果の高い方法でワークロードを AWS で実行できるように、Amazon EC2 インスタンスタイプの推奨事項を必要としているなら？</summary>

- AWS Migration Hubで推奨インスタンスタイプとコストを自動算出できる

</details>

<details>
<summary>AWS Pricing Calculatorとは？</summary>

- 事前に見積もるツール！！！サービスごとにコストを計算して〜〜みたいな感じで過去の文脈で使ってたら間違いなので注意

</details>

<details>
<summary>API キー + 使用量プランについての注意点は？</summary>

- RESTでしか使えない！RESTは高機能だ
- HTTPで使えないのが選択肢として出てくるので注意

</details>

## 問題集
### 1問目
あるグローバルな製薬会社は、アプリケーションの大部分を AWS 上の Amazon VPC と Amazon EC2 インスタンスに移行しました。ただし、同社はデータ規制要件により、EC2 インスタンス上のアプリケーションが使用するデータベースをオンプレミスのデータセンタ内にとどめています。アプリケーションログは、Amazon CloudWatch に集約しています。この会社は、どの EC2 インスタンスがデータベースに接続されているかをほぼリアルタイムで監視したいと考えています。この会社には、オンプレミスで Splunk を使用する監視ソリューションが既にあります。企業はネットワークトラフィックを Splunk に送信する方法を決定する必要があります。ソリューションアーキテクトは、これらの要件をどのように満たす必要がありますか。

- A. VPC フローログを有効にし、CloudWatch に送信します。定義済みのエクスポート関数を使用して、CloudWatch ログを Amazon S3 バケットに定期的にエクスポートする AWS Lambda 関数を作成します。ACCESS_KEY および SECRET_KEY AWS 認証情報を生成します。これらの認証情報を使用して S3 バケットからログを取得するように Splunk を設定します。
- B. Splunk を宛先として Amazon Data Firehose 配信ストリームを作成します。CloudWatch Logs のサブスクリプションフィルタによって送信されたレコードから、個々のログイベントを抽出する Amazon Data Firehose ストリームプロセッサと共に、前処理を行うための AWS Lambda を構成します。VPC フローログを有効にして、CloudWatch に送信します。ログイベントを Amazon Data Firehose 配信ストリームに送信する CloudWatch Logs サブスクリプションを作成します。
- C. データベースに対して行われたすべてのリクエストを EC2 インスタンスの IP アドレスとともにログに記録するように会社に依頼します。CloudWatch ログを Amazon S3 バケットにエクスポートします。Amazon Athena を使用して、データベース名でグループ化されたログをクエリします。Athena の結果を別の S3 バケットにエクスポートします。AWS Lambda 関数を呼び出して、S3 バケットに配置された新しいファイルをすべて Splunk に自動的に送信します。

<details>
<summary>答え</summary>
B

- 重要な点：アプリログではなく「ネットワークトラフィック」、ほぼリアルタイム、Splunk 連携が前提
- Amazon Data Firehose を Splunk 宛先で使用すると、ほぼリアルタイムで Splunk に配信可能
- つまり B は、VPC Flow Logs → CloudWatch → Firehose → Splunk

</details>

### 2問目
あるデータ分析企業は、オンプレミスのデータセンタ内で動作する単一の仮想サーバーに、データの可視化を行うため、Grafana を構成しています。同社は Grafana を使用して、オンプレミス、AWS クラウドの健全性を確認しています。同社は、Grafana のダッシュボードを作成していますが、作成時間がかかりすぎることに懸念がありました。ダッシュボードは高可用性である必要があり、10 分以上ダウンすることはできません。どの解決策が、運用オーバーヘッドを可能な限り抑えながら、これらの要件を満たすことができますか。

- A. Amazon CloudWatch ダッシュボードに移行します。既存の Grafana ダッシュボードと一致するようにダッシュボードを再作成します。可能な場合は自動ダッシュボードを使用します。
- B. Amazon Managed Grafana ワークスペースを作成します。新しい Amazon CloudWatch データソースを設定します。既存の Grafana インスタンスからダッシュボードをエクスポートします。ダッシュボードを新しいワークスペースにインポートします。
- C. Grafana がプリインストールされた AMI を作成します。このダッシュボードを Amazon Elastic File System（Amazon EFS）に保存します。新しい AMI を使用する Auto Scaling グループを作成します。Auto Scaling グループの初期数、必要数、最大数を 1 に設定します。あと二つのアベイラビリティゾーンに対応する ALB を作成します。

<details>
<summary>答え</summary>
B

- Amazon Managed Grafana は、Grafana を AWS がフルマネージドで提供するサービスです。
- 既存 Grafana ダッシュボードをそのままエクスポート／インポート可能
- CloudWatch など AWS データソースとネイティブ連携

</details>

### 3問目
あるオンラインコミックレンタル会社は、AWS で e コマースアプリケーションを運用しています。アプリケーションは Python ベースで、Scaling グループ内の EC2 インスタンスの Apache Web サーバー層で動作しています。データベース層は、Amazon Aurora MySQL データベースで構成されています。また、Amazon CloudFront ディストリビューションも構成されています。先月のセールイベント中に、ユーザーからショッピングカートにアイテムを追加する際にエラーやタイムアウトが発生したという報告がありました。運用チームは Web サーバーによって作成されたログから、Aurora DB クラスタのパフォーマンスメトリクスを確認しました。ログを収集する前に一部の Web サーバーが終了し、Aurora メトリクスはクエリパフォーマンス分析に十分ではありませんでした。ピークトラフィックイベント中にアプリケーションパフォーマンスの可視性を向上させるために、ソリューションアーキテクトが実行する必要がある手順の組み合わせはどれですか。（3つ選択してください）

- A. Aurora MySQL DB クラスタを設定して、スロークエリとエラーログを Amazon CloudWatch Logs にします。
- B. AWS X-Ray SDK を実装して EC2 インスタンスで受信 HTTP リクエストをトレースし、X-Ray SDK for Python を使用して SQL クエリのトレースを実装します。
- C. スロークエリとエラーログを Amazon Kinesis Data Stream にストリーミングするように Aurora MySQL DB クラスタを設定します。
- D. EC2 インスタンスに Amazon CloudWatch Logs エージェントをインストールして設定し、Apache ログを CloudWatch Logs に送信します。
- E. AWS CloudTrail を有効にして設定し、Amazon EC2 と Aurora からアプリケーションアクティビティを収集して分析します。
- F. Aurora MySQL DB クラスタのパフォーマンスベンチマークを有効にして、ストリームを AWS X-Ray に公開します。

<details>
<summary>答え</summary>
A,B,D

- 「クエリパフォーマンス分析」＝ スロークエリログ
- Auto Scaling 環境ではローカルログ＝消えるので、CloudWatch Logs に送っておけばインスタンス終了後もログが残る
- ストリーム処理はオーバーエンジニアリング
- X-Ray はアプリの処理経路を見るサービスで、Aurora の DB 内部パフォーマンスを受け取る仕組みがない
  - Aurora の Performance Insights は DB 専用の分析機能であり、X-Ray にストリーム公開する連携自体が存在しない。

</details>

### 4問目

ある金融サービス会社は、世界中の何千もの顧客が使用している資産管理製品を持っています。同社は、AWS Organizations を使用しており、AWS Backup を使用した一元的なバックアップ管理を行っています。同社は侵入型ランサムウェア攻撃を懸念しています。この懸念に対処するために、同社は、すべてのバックアップが運用アカウントのルートユーザ資格情報の侵害に対して復元力を備えていなければならないという新しいポリシーを作成しました。この新しい要件を満たす手順の組み合わせはどれですか。（3つ選択してください）

- A. 指定された非運用アカウントの AWS Backup Vault を使用して、クロスアカウントバックアップを実装します。
- B. AWS Backup Vault の変更を制限する SCP を追加します。
- C. AWS Backup Vault Lock をコンプライアンスモードで実装します。
- D. コールド層に少なくとも一つのバックアップが常に存在するように、バックアップの頻度、ライフサイクル、および保持期間を構成します。
- E. 指定された非運用アカウントの Amazon S3 バケットにすべてのバックアップを書き込むように AWS Backup を設定します。S3 バケットで S3 オブジェクトロックが有効になっていることを確認します。
- F. AWS Backup に割り当てられた IAM サービスロールに最小権限アクセスを実装します。

<details>
<summary>答え</summary>
A,B,C

- コールド層（Cold tier）とは、AWS Backup における「長期保存・低頻度アクセス向けのバックアップ保存階層」です。削除不可・改ざん不可を保証する仕組みではない。
- AWS Backup は S3 に直接書き込む設計ではない。関係ない。
- IAM 最小権限は、良いセキュリティ対策だが、root ユーザー侵害には無力

</details>

### 5問目

ある企業は EC2 インスタンスの利用状況を確認し、不要に大きいインスタンスを特定してコスト最適化を行いたいと考えています。次の 2 つの要件に対して、最も適切な AWS サービスの組み合わせをそれぞれ答えてください。

- CPU 使用率のみを基に、使用率の低い EC2 インスタンスを特定したい場合
- メモリ使用量を含めて、適切な EC2 インスタンスタイプを選定したい場合

<details>
<summary>答え</summary>

- AWS Trusted Advisor
  - Trusted Advisor は CloudWatch の CPU 使用率を基に、長期間使用率の低い EC2 インスタンスを検出し、コスト最適化の観点から改善点を提示できる。
- CloudWatch Agent + AWS Compute Optimizer
  - CloudWatch Agent によりメモリ使用量を CloudWatch に送信し、その実測データを基に Compute Optimizer が分析を行うことで、メモリを含めた適切な EC2 インスタンスタイプの推奨を取得できる。

</details>

### 6問目

洪水監視機関は、1 万個以上の水位監視センサーを配備しています。センサーは継続的にデータ更新を送信し、各更新のサイズは 1 MB 未満です。この機関には、オンプレミスのアプリケーションサーバーがあります。これらのサーバーは、センサーからの更新を受信し、生データを人間が読める形式に変換し、その結果をオンプレミスのリレーショナルデータベースサーバーに書き込みます。次に、データアナリストは、単純な SQL クエリを使用してデータを監視します。

機関は、アプリケーション全体の可用性を高め、メンテナンスタスクの実行に必要な労力を削減したいと考えています。アプリケーションサーバーの更新とパッチ適用を含むこれらのメンテナンスタスクは、ダウンタイムの原因となります。アプリケーションサーバーがダウンしている間、残りのサーバーがワークロード全体を処理できないため、センサーからデータが失われます。

機関は、運用のオーバーヘッドとコストを最適化するソリューションを求めています。ソリューションアーキテクトは、センサーデータを収集するために AWS IoT Core を使用することを推奨しています。

- A. センサーデータを Amazon Kinesis Data Firehose に送信します。AWS Lambda 関数を使用して Kinesis Data Firehose データを読み取り、Apache Parquet 形式に変換し、Amazon S3 バケットに保存します。データアナリストに、Amazon Athena を使用してデータをクエリするように指示します。
- B. センサーデータを Amazon Managed Service for Apache Flink アプリケーションに送信し、データを Apache Parquet 形式に変換して Amazon S3 バケットに保存します。データアナリストに Amazon Athena を使用してデータをクエリするように指示します。Amazon Athena を使用してデータをクエリするようにデータアナリストに指示します。

<details>
<summary>答え</summary>
A

- 「Apache Flink」と「Athena」の組み合わせは妥当な構成に見えるが、「Flink」を導入すること自体が過剰な構成であるため間違いです。
- Amazon Managed Service for Apache Flink を介さずとも Amazon Kinesis Data Firehose は、AWS Lamda を使用して Parquet 変換と Amazon S3 配信を提供します。Flink を挟むとコードデプロイ、ジョブ監視、スケール設定など「運用コスト」「複雑性」が増し、可用性向上という目的に逆行します。
- Flink が高機能だからと採用を優先し、Firehose に実装済みのエンリッチ機能を確認していない「サービス選定の思い込み」が原因です。

</details>


### 7問目

ソフトウェア会社は、複数の AWS アカウントとリージョンにあるリソースを使用して AWS でアプリケーションをホストしています。アプリケーションは、us-east-1 リージョンにあるアプリケーション VPC 内の Amazon EC2 インスタンスのグループで実行され、IPv4 CIDR ブロックは 10.10.0.0/16 です。別の AWS アカウントでは、共有サービス VPC は us-east-2 リージョンにあり、IPv4 CIDR ブロックは 10.10.10.0/24 です。クラウドエンジニアが AWS CloudFormation を使用してアプリケーション VPC と共有サービス VPC をピアリングしようとすると、ピアリングの失敗を示すエラーメッセージが表示されます。

このエラーの原因となる可能性のある要因を選択してください。 (2 つ選択)

- A. 2 つの VPC の IPv4 CIDR 範囲が重複しています。
- B. VPC が同じリージョンにありません。
- C. 一方または両方のアカウントがインターネットゲートウェイにアクセスできません。
- D. VPC の 1 つが AWS Resource Access Manager を介して共有されていません。
- E. ピアアクセプタのアカウントの IAM ロールに適切な権限がありません。

<details>
<summary>答え</summary>
A,E
</details>

### 8問目

ある会社が、AWS CloudFormation スタックにデプロイされた AWS Lambda に基づいてアプリケーションを構築しました。ウェブアプリケーションの最後の本番リリースで問題が発生し、数分間の停止が発生しました。ソリューションアーキテクトは、カナリアリリースをサポートするためにデプロイプロセスを調整しなければなりません。これらの要件を満たすソリューションはどれですか？

- A. Lambda 関数の新しくデプロイされたバージョンごとにエイリアスを作成します。
- B. アプリケーションを新しい CloudFormation スタックにデプロイします。Amazon Route 53 加重ルーティングポリシーを使用して、負荷を分散します。
- C.新しくデプロイされた Lambda 関数ごとにバージョンを作成します。AWS CLI update-function-configuration コマンドに routing-config パラメーターを指定して負荷を分散します。

<details>
<summary>答え</summary>
A

- Bを間違えて選んでしまった
- AWS Lambda 関数のエイリアス 機能は、バージョンごとのトラフィック重み付けをサポートし、update-alias コマンドの routing-config パラメータによって新旧バージョン間の割合を数パーセント単位で調整できます。
  - これにより、本番トラフィックの一部だけを新バージョンにルーティングし、エラーが発生した場合は即座に重みを 0 % に戻すだけでロールバックできます。
- Route 53 の加重ルーティング はドメイン名レベルのリクエスト分配しか行えず、AWS Lambda 関数のバージョン間で割合を制御する機能を持ちません。そのため DNS 側で重みを設定しても単一エンドポイント内の新旧コードを段階移行できず、本番停止リスクを低減できません。
- https://zenn.dev/tn_a/articles/6918b1059dc156

</details>

### 10問目

ウェザーサービスは、eu-west-1 リージョンの AWS 上でホストされているウェブアプリケーションから高解像度の天気図を提供しています。天気図は頻繁に更新され、静的な HTML コンテンツとともに Amazon S3 に保存されます。ウェブアプリケーションの前面には Amazon CloudFront があります。同社は最近、us-east-1 リージョンのユーザーにサービスを提供するように拡大しました。これらの新しいユーザーは、それぞれの天気図の表示が遅い場合があると報告しています。

us-east-1 のパフォーマンスの問題を解決する手順の組み合わせを選択してください。 (2 つ選択)

- A. AWS Global Accelerator のエンドポイントを eu-west-1 の S3 バケットに設定します。us-east-1 の TCP ポート 80 と 443 に対してエンドポイントグループを構成します。
- B. us-east-1 に新しい S3 バケットを作成します。eu-west-1 の S3 バケットから同期するように S3 クロスリージョンレプリケーションを設定します。
- C. Lambda@Edge を使用して、北米からのリクエストが us-east-1 の S3 Transfer Acceleration エンドポイントを使用するように変更します。
- D. Lambda@Edge を使用して、北米からのリクエストが us-east-1 の S3 バケットを使用するように変更します。
- E. CloudFront ディストリビューションのオリジンとして us-east-1 の AWS Global Accelerator エンドポイントを設定します。Lambda@Edge を使用して、新しいオリジンを使用するように北米からのリクエストを変更します。

<details>
<summary>答え</summary>
B,D
</details>

### 11問目

ある企業では、1 万個以上のセンサーがあり、MQTT (Message Queuing Telemetry Transport) プロトコルを使用して、オンプレミスの Apache Kafka サーバーにデータを送信しています。オンプレミスの Kafka サーバーに接続された別のプロセスがデータを変換し、その結果を Amazon S3 バケットにオブジェクトとして保存します。

最近、Kafka サーバーに障害が発生しました。これにより同社は、サーバーの復旧作業中にセンサーデータを失いました。ソリューションアーキテクトは、同様の事態を防ぐために、可用性と拡張性に優れた新しい設計を AWS 上に作成する必要があります。

運用上のオーバーヘッドが最も少なく、これらの要件を満たすソリューションを選択してください。

- A. AWS IoT Core をデプロイし、Amazon EC2 インスタンスを起動して Kafka サーバーをホストします。AWS loT Core は、EC2 インスタンスにデータを送信するように構成します。センサーをルーティングして、AWS IoT Core にデータを送信します。
- B. オンプレミスの Kafka サーバーを Amazon Managed Streaming for Apache Kafka (Amazon MSK) に移行します。Amazon MSK ブローカーを指す Network Load Balancer (NLB) を作成します。NLB ヘルスチェックを有効にします。センサーをルーティングして、NLB にデータを送信します。
- C. AWS IoT Core をデプロイし、Amazon Kinesis Data Firehose 配信ストリームに接続します。AWS Lambda 関数を使用してデータ変換を処理します。センサーをルーティングして、AWS IoT Core にデータを送信します。
- D. 2 つの Amazon EC2 インスタンスを起動して、2 つのアベイラビリティーゾーンにまたがるアクティブ / スタンバイ構成で Kafka サーバーをホストします。Amazon Route 53 でドメイン名を作成します。Route 53 フェイルオーバーポリシーを作成します。センサーをルーティングしてデータをドメイン名に送信します。

<details>
<summary>答え</summary>
C
</details>

### ✅ 12問目

ソリューションアーキテクトが、新しいセキュリティツールを、これまで使われていなかったいくつかの AWS リージョンにデプロイする準備をしています。ソリューションアーキテクトは、AWS CloudFormation StackSets を使用してツールをデプロイします。StackSets のテンプレートには、カスタム名を持つ IAM ロールが含まれています。StackSets の作成時に、スタックインスタンスが正常に作成されません。

スタックを正常にデプロイする最適な方法を選択してください。

- A. すべての関連アカウントで新しいリージョンを有効にします。StackSets の作成時に、CAPABILITY_NAMED_IAM 機能を指定します。
- B. Service Quotas コンソールを使用して、関連するすべてのアカウントで、各新しいリージョンの CloudFormation スタックの数のクォータの増加をリクエストします。StackSets の作成時に、CAPABILITY_IAM 機能を指定します。
- C. StackSets の作成時に、CAPABILITY_NAMED_IAM 機能と SELF_MANAGED アクセス許可モデルを指定します。
- D. StackSets の作成時に、管理ロールの ARN と CAPABILITY_IAM 機能を指定します。

<details>
<summary>答え</summary>
A

- AWS CloudFormation StackSets は、テンプレート内でカスタム名を指定した IAM Role を作成する場合、StackSets 実行時に CAPABILITY_NAMED_IAM を宣言する必要があります。これを宣言しないと CloudFormation は名前付きロールの作成を拒否し、スタックインスタンスが ROLLBACK_COMPLETE となります。

</details>

### 13問目

ある企業は、ユーザー向けのインフラストラクチャサービスのプラットフォームを構築しています。この企業には以下のような要件があります。

- AWS インフラストラクチャの起動時にユーザーに最小限の特権アクセスを提供し、ユーザーが承認されていないサービスをプロビジョニングできないようにします。
- インフラサービスの作成を中央アカウントで管理します。
- AWS Organizations の複数のアカウントにインフラストラクチャサービスを配布する機能を提供します。
- ユーザーが起動したインフラストラクチャにタグを適用する機能を提供します。

これらの要件を満たす AWS サービスを利用したアクションの組み合わせを選択してください。 (3 つ選択)

- A. AWS CloudFormation テンプレートを使用してインフラストラクチャサービスを開発します。テンプレートを中央の Amazon S3 バケットに追加し、S3 バケットポリシーへのアクセスを必要とする IAM ロールまたはユーザーを追加します。
- B. AWS CloudFormation テンプレートを使用してインフラストラクチャサービスを開発します。各テンプレートを AWS Service Catalog 製品として、中央の AWS アカウントで作成したポートフォリオにアップロードします。これらのポートフォリオを、会社用に作成した組織構造と共有します。
- C. ユーザーの IAM ロールに AWSCloudFormationFullAccess と AmazonS3ReadOnlyAccess 権限を持つことを許可します。AWS アカウントのルートユーザーレベルでOrganizations の SCP を追加して、AWS CloudFormation と Amazon S3 以外ののすべてのサービスを拒否します。
- D. ユーザーの IAM ロールに ServiceCatalogEndUserAccess アクセス許可のみを許可します。自動化スクリプトを使用して、中央ポートフォリオをローカル AWS アカウントにインポートし、TagOption をコピーし、ユーザーにアクセス割り当て、起動制約を適用します。
- E. AWS Service Catalog TagOption ライブラリを使用して、会社が必要とするタグのリストを維持します。TagOption を AWS Service Catalog の製品またはポートフォリオに適用します。
- F. AWS CloudFormation リソースタグのプロパティを使用して、ユーザー用に作成される CloudFormation テンプレートにタグを適用します。

<details>
<summary>答え</summary>
B,D,E
</details>

### 14問目

ある会社は、マイクロサービスに基づいた新しいオンデマンドビデオアプリケーションを開発しています。このアプリケーションのユーザー数は開始時に 500 万人、6 ヶ月後には 3,000 万人になる予定です。同社はこのアプリケーションを AWS Fargate 上の Amazon Elastic Container Service (Amazon ECS) にデプロイしました。同社は、HTTPS プロトコルを使用する ECS サービスを使用してアプリケーションを開発しました。

ソリューションアーキテクトは、ブルー / グリーンデプロイを使用してアプリケーションの更新を実装する必要があります。ソリューションは、ロードバランサーを介して各 ECS サービスにトラフィックを分散する必要があります。アプリケーションは、Amazon CloudWatch のアラームに応答して、タスク数を自動的に調整する必要があります。

これらの要件を満たすソリューションを選択してください。

- A.	ブルー / グリーンデプロイタイプと Network Load Balancer を使用するように ECS サービスを構成します。需要を満たすために、サービスごとのタスクのサービスクォータの増加を要求します。
- B.	ブルー / グリーンデプロイタイプと Network Load Balancer を使用するように ECS サービスを構成します。Cluster Autoscaler を使用して、ECS サービスごとに Auto Scaling グループを実装します。
- C. ブルー / グリーンデプロイタイプと Application Load Balancer を使用するように ECS サービスを構成します。Cluster Autoscaler を使用して、ECS サービスごとに Auto Scaling グループを実装します。
- D. ブルー / グリーンデプロイタイプと Application Load Balancer を使用するように ECS サービスを構成します。ECS サービスごとに Service Auto Scaling を実装します。

<details>
<summary>答え</summary>
D
</details>

### 15問目

ある映像処理会社が、オンプレミスのネットワーク接続ストレージシステムに何千ものファイルとして保存されている 600 TB の圧縮データを利用して、機械学習 (ML) モデルを作成したいと考えています。この企業は、オンプレミスでは機械学習の研究に必要な計算能力が不足しているため、AWS の利用を希望しています。
3 週間以内に、AWS へのデータ移行を完了する必要があります。データ転送は 1 回だけ行われます。転送中のデータの暗号化が必要です。同社のインターネット接続のアップロード速度は 100 Mbps と測定されており、多くの部門で共有されています。
これらの要件を満たすために最も費用対効果の高い方法を選択してください。

- A. AWS マネジメントコンソールを使用して、複数の AWS Snowball Edge Storage Optimized デバイスを注文します。宛先 を S3 バケットとしてデバイスを設定します。データをデバイスにコピーします。デバイスを AWS に返送します。
- B. 会社の場所と最も近い AWS リージョンの間に 10 Gbps の AWS Direct Connect 接続を設定します。VPN 接続を介してデータをリージョンに転送し、Amazon S3 にデータを保存します。
- C. オンプレミスのネットワークストレージと最も近い AWS リージョンの間に VPN 接続を作成します。VPN 接続を介してデータを転送します。
- D. オンプレミスに AWS Storage Gateway ファイルゲートウェイをデプロイします。宛先 をS3 バケットとしてファイルゲートウェイを設定します。データをファイルゲートウェイにコピーします。

<details>
<summary>答え</summary>
A
</details>

ある企業がレイテンシーの影響を受けやすいアプリケーションを開発しています。アプリケーションの一部には、できるだけ早く初期化する必要があるいくつかの AWS Lambda 関数が含まれています。Lambda 関数は Java で記述されており、ライブラリのロード、クラスの初期化、一意な ID の生成のための初期化コードがハンドラーの外側に含まれています。

最もコスト効率よく起動パフォーマンス要件を満たすソリューションを選択してください。

- A. すべての初期化コードを各 Lambda 関数のハンドラーに移動します。各 Lambda 関数で Lambda SnapStart を有効にします。各 Lambda 関数の $LATEST バージョンを参照するように SnapStart を構成します。
- B. 各 Lambda 関数のバージョンを公開します。各 Lambda 関数のエイリアスを作成します。各エイリアスが対応するバージョンを指すように設定します。各 Lambda 関数が対応するエイリアスを指すようにプロビジョニング済み同時実行設定を設定します。
- C. 各 Lambda 関数のバージョンを公開します。各 Lambda 関数が対応するバージョンを指すようにプロビジョニング済み同時実行設定を設定します。Lambda 関数の公開バージョンに対して Lambda SnapStart を有効します。
- D. Lambda 関数を更新して、スナップショット前のフックを追加します。一意の ID を生成するコードをハンドラーに移動します。各 Lambda 関数のバージョンを公開します。Lambda 関数の公開バージョンで Lambda SnapStart を有効にします。

<details>
<summary>答え</summary>
D
</details>

### 16問目

ある大手モバイルゲーム会社は、オンプレミスのインフラストラクチャから AWS クラウドへ移行しました。ソリューションアーキテクトは、環境が設計通りに構築され、AWS Well-Architected フレームワークに従って運用されていることを確認するために、環境の評価を行っています。
ソリューションアーキテクトは、AWS Cost Explorer で過去の月額使用料を分析しているときに、さまざまな大きなインスタンスタイプの作成とその後の終了に、不釣り合いな量のリソースが使用されていることがわかりました。ソリューションアーキテクトは、会社の開発者がテスト目的で新しい Amazon EC2 インスタンスを作成しており、正しいインスタンスタイプを利用していないことを発見しました。

ソリューションアーキテクトは、開発者だけが起動できるインスタンスタイプを制限する方法を設計する必要があります。これらの基準を満たすソリューションを選択してください。

- A. AWS Config で希望するインスタンスタイプのマネージドルールを作成します。許可されるインスタンスタイプでルールを構成します。ルールをイベントにアタッチして、新しい EC2 インスタンスが起動されるたびに実行します。
- B. EC2 コンソールで、許可されるインスタンスタイプを指定する起動テンプレートを作成します。起動テンプレートを開発者の IAM アカウントに割り当てます。
- C. 新しい IAM ポリシーを作成します。許可されるインスタンスタイプを指定します。開発者の IAM アカウントを含む IAM グループにポリシーをアタッチします。
- D. EC2 Image Builder を使用して、開発者向けのイメージパイプラインを作成し、ゴールデンイメージの作成を支援します。

<details>
<summary>答え</summary>
C

- Dと答えてしまった

</details>

### 17問目

ある企業はアプリケーションを AWS クラウドに移行しています。このアプリケーションは、オンプレミスのデータセンターで実行され、毎晩、マウントされた NFS ファイルシステムに何千ものイメージが書き込まれます。企業はアプリケーションを移行した後、Amazon Elastic File System (Amazon EFS) ファイルシステムがマウントされた Amazon EC2 インスタンスでアプリケーションをホストします。

同社は、AWS への AWS Direct Connect 接続を確立しました。移行カットオーバーの前に、ソリューションアーキテクトは、新しく作成されたオンプレミスイメージを EFS ファイルシステムに複製するプロセスを構築する必要があります。

イメージを複製する最も運用効率の高い方法を選択してください。

- A. オンプレミスのファイルシステムから Amazon S3 に aws s3 sync コマンドを実行する定期的なプロセスを設定します。AWS Lambda 関数を構成して、Amazon S3 からのイベント通知を処理し、Amazon S3 から EFS ファイルシステムにイメージをコピーします。
- B. NFS マウントポイントを持つ AWS Storage Gateway ファイルゲートウェイをデプロイします。オンプレミスサーバーにファイルゲートウェイのファイルシステムをマウントします。マウントポイントに定期的にイメージをコピーするプロセスを構成します。
- C. NFS ファイルシステムにアクセスできるオンプレミスサーバーに AWS DataSync エージェントをデプロイします。パブリック VIF を使用して、Direct Connect 接続経由で S3 バケットにデータを送信します。AWS Lambda 関数を構成して、Amazon S3 からのイベント通知を処理し、Amazon S3 から EFS ファイルシステムにイメージをコピーします。
- D. NFS ファイルシステムにアクセスできるオンプレミスサーバーに AWS DataSync エージェントをデプロイします。プライベート VIF を使用して、Amazon EFS 用の AWS PrivateLink インターフェイス VPC エンドポイントに Direct Connect 接続経由でデータを送信します。24 時間ごとに EFS ファイルシステムにイメージを送信するように DataSync スケジュールされたタスクを構成します。

<details>
<summary>答え</summary>
D

- Cと答えてしまった

</details>

### 18問目

ある企業は、レガシーアプリケーションをオンプレミスのデータセンターから AWS に移行しています。このアプリケーションは、キーと値のデータベースとして MongoDB を使用します。同社の技術ガイドラインによると、すべての Amazon EC2 インスタンスは、インターネット接続のないプライベートサブネットでホストする必要があります。さらに、アプリケーションとデータベース間の接続はすべて暗号化する必要があります。データベースは、需要に基づいて拡張できる必要があります。

これらの要件を満たすソリューションを選択してください。

- A. プロビジョンド IOPS ボリュームを使用して、アプリケーション用に新しい Amazon DocumentDB テーブルを作成します。インスタンスエンドポイントを使用して Amazon DocumentDB に接続します。
- B. オンデマンドキャパシティでアプリケーション用に新しい Amazon DynamoDB のテーブルを作成します。DynamoDB のゲートウェイ VPC エンドポイントを使用して、DynamoDB テーブルに接続します。
- C. オンデマンドキャパシティでアプリケーション用に新しい Amazon DynamoDB のテーブルを作成します。DynamoDB のインターフェイス VPC エンドポイントを使用して、DynamoDB テーブルに接続します。
- D. プロビジョンド IOPS ボリュームを使用して、アプリケーション用に新しい Amazon DocumentDB テーブルを作成します。クラスターエンドポイントを使用して、Amazon DocumentDB に接続します。

<details>
<summary>答え</summary>
B

- Aと答えてしまった
- この問題は 「MongoDB互換」よりも「要件充足」 を優先させる問題。

</details>

### ✅ 19問目

ある大企業では先日、Amazon RDS と Amazon DynamoDB のコストが予想外に増加しました。同社は、AWS の請求とコスト管理の遅延に対する可視性を高める必要があります。AWS Organizations に関連するアカウントは、開発アカウントや本番アカウントなど様々なものがあります。組織全体で一貫したタグ付け戦略はありません。一方で、一貫したタグ付けを使用して AWS CloudFormation を使用してすべてのインフラストラクチャをデプロイすることを要求するガイドラインがあります。管理には、既存および将来のすべての DynamoDB テーブルと RDS リソースについて、コストセンター番号とプロジェクト ID 番号が必要です。

これらの要件を満たすための最適な戦略を選択してください。

- A. タグエディタを使用して、既存のリソースにタグを付けます。コスト配分タグを作成してコストセンターとプロジェクト ID を定義し、タグが既存のリソースに伝播するまで 24 時間待ちます。
- B. AWS Config ルールを使用して、タグ付けされていないリソースについて財務チームに警告します。クロスアカウントロールを使用して、タグ付けされていない RDS データベースと DynamoDB リソースに 1 時間ごとにタグを付ける、一元化された AWS Lambda ベースのソリューションを作成します。
- C. タグエディタを使用して、既存のリソースにタグを付けます。コスト配分タグを作成し、コストセンターとプロジェクト ID を定義します。SCP を使用して、リソースにコストセンターとプロジェクト ID を持たないリソースの作成を制限します。
- D. コスト配分タグを作成してコストセンターとプロジェクト ID を定義し、タグが既存のリソースに伝播するまで 24 時間待ちます。既存のフェデレーションロールを更新して、リソースにコストセンターとプロジェクト ID を含まないリソースをプロビジョニングする特権を制限します。

<details>
<summary>答え</summary>
D
</details>

### ✅ 20問目

ある企業では、すべての社内アプリケーション接続でプライベート IP アドレスを使用することを義務付けています。このポリシーを容易にするために、ソリューションアーキテクトは AWS パブリックサービスに接続するためのインターフェイスエンドポイントを作成しました。テスト時に、ソリューションアーキテクトは、サービス名がパブリック IP アドレスに解決され、内部サービスがインターフェイスエンドポイントに接続できないことに気づきました。

この問題を解決するためにソリューションアーキテクトが実行すべき手順を選択してください。

- A. インターフェイスエンドポイントへのルートでサブネットのルートテーブルを更新します。
- B. VPC 属性でプライベート DNS オプションを有効にします。
- C. インターフェイスエンドポイントでセキュリティグループを構成して、AWS サービスへの接続を許可します。
- D. 社内アプリケーション用の条件付きフォワーダーを使用して Amazon Route 53 プライベートホストゾーンを構成します。

<details>
<summary>答え</summary>
B
</details>

### 21問目

ソリューションアーキテクトは、手動で作成された既存の開発環境の AWS 環境から AWS CloudFormation テンプレートを作成しています。CloudFormation テンプレートは必要に応じて破棄し、再作成することができます。環境には Amazon EC2 インスタンスが含まれています。EC2 インスタンスには、EC2 インスタンスが親アカウントのロールを引き受けるために使用するインスタンスプロファイルがあります。

ソリューションアーキテクトは、CloudFormation テンプレートでロールを再作成し、同じロール名を使用します。CloudFormation テンプレートが子アカウントで起動されると、EC2 インスタンスは権限が不十分なため、親アカウントのロールを引き受けることができなくなります。

この問題を解決するための最適な方法を選択してください。

- A. 親アカウントで、EC2 インスタンスが引き受ける必要のあるロールの信頼ポリシーを編集します。sts:AssumeRole アクションを許可する既存のステートメントのターゲットロールの ARN が正しいことを確認します。信頼ポリシーを保存します。
- B. 親アカウントで、EC2 インスタンスが引き受ける必要のあるロールの信頼ポリシーを編集します。子アカウントのルートプリンシパルに sts:AssumeRole アクションを許可するステートメントを追加します。信頼ポリシーを保存します。
- C. CloudFormation スタックを再度更新します。CAPABILITY_NAMED_IAM 機能のみを指定します。
- D. CloudFormation スタックを再度更新します。CAPABILITY_IAM 機能と CAPABILITY_NAMED_IAM 機能を指定します。

<details>
<summary>答え</summary>
A

- 原因は「同じロール名でも、再作成された IAM ロールは別物（ARN が変わる）」であり、親アカウント側の信頼ポリシーが古い ARN を参照したままになっているため。
- CAPABILITY_IAM / CAPABILITY_NAMED_IAM はCloudFormation が IAM リソースを作成する許可。スタック作成は成功しているため、問題点ではない
- 「AssumeRole できない」原因は 信頼ポリシー

</details>

### 21問目

ある企業は、自社の AWS 環境からのアウトバウンドのトラフィックを監視および保護するために、AWS Marketplace からサードパーティーのファイアウォールアプライアンスソリューションをデプロイしています。同社は、このアプライアンスを共有サービス VPC にデプロイし、すべてのアウトバウンドのインターネット行きのトラフィックをアプライアンス経由でルーティングしたいと考えています。

ソリューションアーキテクトは、信頼性を優先し、単一の AWS リージョン内のファイアウォールアプライアンス間のフェイルオーバー時間を最小限に抑える導入方法を推奨する必要があります。同社は、共有サービス VPC から他の VPC へのルーティングを設定しています。

これらの要件を満たす最適な手順を選択してください。(3 つ選択)

- A. 2 つのファイアウォールアプライアンスを共有サービス VPC にデプロイし、それぞれを別のアベイラビリティーゾーンに配置します。
- B. 共有サービス VPC に新しい Network Load Balancer を作成します。新しいターゲットグループを作成し、それを新しい Network Load Balancer にアタッチします。各ファイアウォールアプライアンスインスタンスをターゲットグループに追加します。
- C. 共有サービス VPC に新しい Gateway Load Balancer を作成します。新しいターゲットグループを作成し、新しい Gateway Load Balancer にアタッチします。各ファイアウォールアプライアンスインスタンスをターゲットグループに追加します。
- D. VPC インターフェイスのエンドポイントを作成します。共有サービス VPC のルートテーブルにルートを追加します。他の VPC から共有サービス VPC に入るトラフィックのネクストホップとして新しいエンドポイントを指定します。
- E. 共有サービス VPC に 2 つのファイアウォールアプライアンスを、それぞれ同じアベイラビリティーゾーンに配備します。
- F. VPC Gateway Load Balancer エンドポイントを作成します。共有サービス VPC のルートテーブルにルートを追加します。新しいエンドポイントを、他の VPC から共有サービス VPC に入るトラフィックのネクストホップとして指定します。

<details>
<summary>答え</summary>
A,C,F
</details>

### 22問目

ある企業は、AWS 上でデータ集約型のアプリケーションを実行しています。このアプリケーションは、数百の Amazon EC2 インスタンスのクラスター上で実行されています。また、200 TB のデータを保存する共有ファイルシステムも、いくつかの EC2 インスタンス上で実行されています。アプリケーションは、共有ファイルシステム上のデータを読み込んで変更し、レポートを生成します。このジョブは毎月 1 回実行され、共有ファイルシステムからファイルのサブセットを読み取り、完了するまでに約 72 時間かかります。コンピューティングインスタンスは Auto Scaling グループでスケーリングされますが、共有ファイルシステムをホストするインスタンスは継続的に実行されます。コンピューティングインスタンスとストレージインスタンスは、すべて同じ AWS リージョンにあります。

ソリューションアーキテクトは、共有ファイルシステムのインスタンスを置き換えることによってコストを削減する必要があります。ファイルシステムは、72 時間の実行中に、必要なデータへの高性能アクセスを提供する必要があります。

これらの要件を満たしながら、全体的なコストを最大に削減できるソリューションを選択してください。

- A. 既存の共有ファイルシステムから、S3 Intelligent-Tiering ストレージクラスを使用する Amazon S3 バケットにデータを移行します。毎月のジョブが実行される前に、Amazon FSx for Lustre を使用して、遅延ロードを使用して Amazon S3 からのデータで新しいファイルシステムを作成します。ジョブの実行期間中は、新しいファイルシステムを共有ストレージとして使用します。ジョブが完了したら、ファイルシステムを削除します。
- B. 既存の共有ファイルシステムから、マルチアタッチを有効にした大きな Amazon Elastic Block Store (Amazon EBS) ボリュームにデータを移行します。Auto Scaling グループの起動テンプレートのユーザーデータスクリプトを使用して、EBS ボリュームを各インスタンスにアタッチします。ジョブの実行期間中、EBS ボリュームを共有ストレージとして使用します。ジョブが完了したら、EBS ボリュームをデタッチします。
- C. 既存の共有ファイルシステムから、S3 標準ストレージクラスを使用する Amazon S3 バケットにデータを移行します。毎月のジョブを実行する前に、Amazon FSx for Lustre を使用して、バッチによる読み込みを使用して Amazon S3 からのデータで新しいファイルシステムを作成します。ジョブの実行期間中は、新しいファイルシステムを共有ストレージとして使用します。ジョブが完了したら、ファイルシステムを削除します。
- D. 既存の共有ファイルシステムから Amazon S3 バケットにデータを移行します。毎月のジョブを実行する前に、AWS Storage Gateway を使用して、Amazon S3 からのデータでファイルゲートウェイを作成します。ジョブ用の共有ストレージとしてファイルゲートウェイを使用します。ジョブが完了したら、ファイルゲートウェイを削除します。

<details>
<summary>答え</summary>
A
</details>

### 23問目

ある会社は、AWS Organizations の組織を使用して、会社の AWS アカウントを管理しています。同社は AWS CloudFormation を使用してすべてのインフラストラクチャをデプロイしています。財務チームはチャージバックモデルを構築したいと考えています。財務チームは、定義済みのプロジェクト値のリストを使用して、各事業部にリソースのタグ付けを依頼しました。財務チームが AWS Cost Explorer の AWS コストと使用状況レポートを使用し、プロジェクトに基づいてフィルタリングしたところ、コンプライアンスに反するプロジェクト値に気づきました。

会社は、新しいリソースに対してプロジェクトタグの使用を強制したいと考えています。

最小限の労力でこれらの要件を満たすソリューションを選択してください。

- A. 組織の管理アカウントで、許可されたプロジェクトタグ値を含むタグポリシーを作成します。プロジェクトタグが追加されない限り、cloudformation:CreateStack API オペレーションを拒否する SCP を作成します。各 OU に SCP をアタッチします。
- B. 各 OU で許可されるプロジェクトタグ値を含むタグポリシーを作成します。プロジェクトタグが追加されない限り、cloudformation:CreateStack API オペレーションを拒否する SCP を作成します。各 OU に SCP をアタッチします。
- C. AWS 管理アカウントで、許可されるプロジェクトタグ値を含むタグポリシーを作成します。プロジェクトタグが追加されない限り、cloudformation:CreateStack API オペレーションを拒否する IAM ポリシーを作成します。このポリシーを各ユーザーに割り当てます。
- D. AWS Service Catalog を使用して、CloudFormation スタックを製品として管理します。TagOptions ライブラリを使用して、プロジェクトのタグ値を制御します。組織内のすべての OU とポートフォリオを共有します。

<details>
<summary>答え</summary>
A
</details>

### 24問目

企業は AWS クラウドでウェブアプリケーションを実行しています。このアプリケーションは、一連の Amazon EC2 インスタンスで作成される動的コンテンツで構成されています。EC2 インスタンスは、Application Load Balancer (ALB) のターゲットグループとして設定された Auto Scaling グループで実行されています。

同社は、Amazon CloudFront ディストリビューションを使用して、アプリケーションをグローバルに配布しています。CloudFront ディストリビューションは、ALB をオリジンとして使用します。同社は DNS に Amazon Route 53 を使用し、CloudFront ディストリビューション用に www.example.com (http://www.example.com) の A レコードを作成しました。

ソリューションアーキテクトは、アプリケーションの可用性と耐障害性を高めるようにアプリケーションを構成する必要があります。これらの要件を満たすソリューションを選択してください。

- A. 別の AWS リージョンで、完全なセカンダリアプリケーションのデプロイをプロビジョニングします。Route 53 の A レコードをフェイルオーバーレコードに更新します。値として CloudFront ディストリビューションの両方を追加します。Route 53 ヘルスチェックを作成します。
- B. ALB、Auto Scaling グループ、および EC2 インスタンスを別の AWS リージョンにプロビジョニングします。CloudFront ディストリビューションを更新し、新しい ALB 用に 2 番目のオリジンを作成します。2 つのオリジンに対してオリジングループを作成します。1 つのオリジンをプライマリとして構成し、1 つのオリジンをセカンダリとして構成します。
- C. Auto Scaling グループと EC2 インスタンスを別の AWS リージョンにプロビジョニングします。ALB に新しい Auto Scaling グループ用の 2 番目のターゲットを作成します。ALB にフェイルオーバールーティングアルゴリズムを設定します。
- D. 別の AWS リージョンで、完全なセカンダリアプリケーションのデプロイをプロビジョニングします。2 番目の CloudFront ディストリビューションを作成し、オリジンとして新しいアプリケーションの設定を追加します。AWS Global Accelerator アクセラレータを作成します。両方の CloudFront ディストリビューションをエンドポイントとして追加します。

<details>
<summary>答え</summary>
B

- Route53のフェイルオーバールーティングか、Cloudfrontのオリジングループかは見極め必要
- アプリは生きているが一部 5xx が出る
  - CloudFront オリジングループ
- リージョン障害や ALB ごと落ちる
  - Route 53 フェイルオーバー

</details>

### 25問目

ある企業は、サードパーティの SaaS アプリケーションを使用したいと考えています。サードパーティの SaaS アプリケーションは、いくつかの API 呼び出しによって消費されます。サードパーティの SaaS アプリケーションは、VPC 内の AWS で実行されます。

同社は、VPC 内からサードパーティの SaaS アプリケーションを利用する予定です。同社には、インターネットを経由しないプライベート接続の使用を義務付ける社内セキュリティポリシーがあります。会社の VPC 内で実行されるリソースは、同社の VPC 外からのアクセスを許可されません。すべてのアクセス許可は、最小特権の原則に準拠する必要があります。

これらの要件を満たすソリューションを選択してください。

- A. AWS PrivateLink インターフェース VPC エンドポイントを作成します。このエンドポイントを、サードパーティの SaaS アプリケーションが提供するエンドポイントサービスに接続します。エンドポイントへのアクセスを制限するセキュリティグループを作成します。セキュリティグループをエンドポイントに関連付けます。
- B. サードパーティの SaaS アプリケーションと会社の VPC の間に AWS Site-to-Site VPN 接続を作成します。VPN トンネル間のアクセスを制限するためにネットワーク ACL を構成します。
- C. サードパーティの SaaS アプリケーションと会社の VPC の間に VPC ピアリング接続を作成します。ピアリング接続に必要なルートを追加して、ルートテーブルを更新します。
- D. AWS PrivateLink エンドポイントサービスを作成します。サードパーティの SaaS プロバイダーに、このエンドポイントサービス用のインターフェース VPC エンドポイントを作成するように依頼します。サード パーティの SaaS プロバイダーの特定のアカウントに、エンドポイントサービスのアクセス許可を付与します。

<details>
<summary>答え</summary>
A

-「VPC ピアリング」では、最小特権のアクセス制御やサービス単位の制御が難しいため間違いです。
- VPC ピアリング を使用すると両 VPC の CIDR 間でルーティングが成立し、SaaS 側からも自社 VPC への到達が可能になります。セキュリティグループやルートで細かく制限しても、サービスレベルで必要な「一方向」「エンドポイント単位」通信を実装しにくく、想定外アクセスのリスクが残るため要件を満たしません。
- 「VPC ピアリング」が提供する双方向性と 「AWS PrivateLink」 の一方向性の違いを対比し、最小特権設計に適合する接続方式を復習してください。

</details>

### 26問目

ある会社は多くの AWS アカウントを持っており、AWS Organizations を使用してすべてのアカウントを管理しています。ソリューションアーキテクトは、同社が複数のアカウントで共通のネットワークを共有するために使用できるソリューションを実装する必要があります。

同社のインフラストラクチャチームは、VPC を持つ専用のインフラストラクチャアカウントがあります。インフラストラクチャチームは、このアカウントを使用してネットワークを管理する必要があります。個々のアカウントは、独自のネットワークを管理する能力を持つことはできません。ただし、個々のアカウントはサブネット内に AWS リソースを作成できる必要があります。

これらの要件を満たす最適な方法の組み合わせを選択してください。 (2 つ選択)

- A. インフラストラクチャのアカウントで Transit Gateway を作成します。
- B. AWS Organizations の管理アカウントからリソース共有を有効にします。
- C. AWS Organizations の組織内の各 AWS アカウントに VPC を作成します。インフラストラクチャのアカウントの VPC と同じ CIDR 範囲とサブネットを共有するように VPC を構成します。個々のアカウントの VPC をインフラストラクチャのアカウントの VPC とピアリングします。
- D. インフラストラクチャのアカウントの AWS Resource Access Manager (RAM) でリソース共有を作成します。共有ネットワークを使用する特定の AWS Organizations OU を選択します。リソース共有に関連付ける各サブネットを選択します。
- E. インフラストラクチャのアカウントの AWS Resource Access Manager (RAM) でリソース共有を作成します。共有ネットワークを使用する特定の AWS Organizations OU を選択します。リソース共有に関連付けるために、各プレフィックスリストを選択します。

<details>
<summary>答え</summary>
B,D

</details>

### 27問目

企業は、ハイブリッド DNS ソリューションを設計する必要があります。このソリューションは、VPC 内に保存されたリソースのために、ドメイン cloud.example.com の Amazon Route 53 プライベートホスティングゾーンを使用する予定です。

同社には、以下の DNS 解決の要件があります。
・オンプレミスシステムは、cloud.example.com を解決して接続できる必要があります。
・すべての VPC が cloud.example.com を解決できる必要があります。

オンプレミスの企業ネットワークと AWS Transit Gateway の間には、すでに AWS Direct Connect 接続が存在します。

最高のパフォーマンスでこれらの要件を満たす最適な方法を選択してください。
- A. プライベートホストゾーンをすべての VPC に関連付けます。共有サービス VPC に Route 53 インバウンドリゾルバを作成します。すべての VPC を Transit Gateway にアタッチし、cloud.example.com のオンプレミスの DNS サーバーに、インバウンドリゾルバーを指す転送ルールを作成します。
- B. プライベートホストゾーンを共有サービス VPC に関連付けます。共有サービス VPC に Route 53 インバウンドリゾルバーを作成します。共有サービス VPC を Transit Gateway にアタッチし、cloud.example.com のオンプレミス DNS サーバーに、インバウンドリゾルバーを指す転送ルールを作成します。

<details>
<summary>答え</summary>
A

- 村中「インバウンドリゾルバはどこかのVPCに属さないといけなくて、そのさいに共有サービスVPCを選んでいるっていうことですか？」
- その理解で合ってる。
  - Route 53 のインバウンドリゾルバ（Route 53 Resolver inbound endpoint）は、必ずどこか1つの VPC 内に作成する必要があります。
  - リゾルバ自体は「アカウント共通」「リージョン共通」で浮いている存在ではなく、VPC のサブネットに ENI を持つ形で配置されます。
  - この選択肢 A では、その配置先として「共有サービス VPC」を選んでいる、という意味になります。

</details>

### 28問目

ある会社は、単一の AWS アカウントで複数のワークロードを実行しています。新しい会社のポリシーは、エンジニアが承認されたリソースのみをプロビジョニングでき、エンジニアはこれらのリソースをプロビジョニングするために AWS CloudFormation を使用しなければなりません。ソリューションアーキテクトは、エンジニアがアクセスに使用する IAM ロールに新しい制限を強制するためのソリューションを作成する必要があります。

ソリューションを作成する最適な方法を選択してください。

- A. 承認されたリソースを含む AWS CloudFormation のテンプレートを Amazon S3 バケットにアップロードします。エンジニアの IAM ロールの IAM ポリシーを更新して、Amazon S3 と AWS CloudFormation へのアクセスのみを許可します。AWS CloudFormation のテンプレートを使用してリソースをプロビジョニングします。
- B. エンジニアの IAM ロールの IAM ポリシーを、承認されたリソースのプロビジョニングと AWS CloudFormation のみを許可する権限に更新します。AWS CloudFormation のテンプレートを使用して、承認されたリソースでスタックを作成します。
- C. エンジニアの IAM ロールの IAM ポリシーを更新し、AWS CloudFormation のアクションのみを許可するアクセス許可を与えます。承認されたリソースをプロビジョニングするアクセス許可を持つ新しい IAM ポリシーを作成し、そのポリシーを新しい IAM サービス ロールに割り当てます。スタックの作成中に IAM サービスロールを AWS CloudFormation に割り当てます。
- D. AWS CloudFormation のスタックにリソースをプロビジョニングします。エンジニアの IAM ロールの IAM ポリシーを更新し、自分の AWS CloudFormation スタックへのアクセスのみを許可します。

<details>
<summary>答え</summary>
C
</details>

### 29問目

ある企業が、自社のデータセンターで稼働するアプリケーションのディザスタリカバリ (DR) ソリューションを設計したいと考えています。このアプリケーションは SMB ファイル共有に書き込み、2 つ目のファイル共有にコピーを作成します。どちらのファイル共有もデータセンターにあります。アプリケーションは、メタデータファイルとイメージファイルの 2 種類のファイルを使用します。AWS 上にコピーを保存したいと考えています。

同社は、災害が発生した場合、データセンターまたは AWS のどちらからでも SMB を使用してデータにアクセスできる機能を必要としています。データのコピーはほとんどアクセスされませんが、5 分以内に利用できる必要があります。

要件を満たす最適な方法を選択してください。

- A. Amazon S3 ストレージを使用して AWS Outposts をデプロイします。Outposts 上の Windows Amazon EC2 インスタンスをファイルサーバーとして構成します。
- B. Amazon FSx File Gateway をデプロイします。SSD ストレージを使用する Amazon FSx for Windows File Server マルチ AZ ファイルシステムを構成します。
- C. Amazon S3 ファイルゲートウェイをデプロイします。メタデータファイルに Amazon S3 標準 - 低頻度アクセス (S3 標準 - IA) を使用し、イメージファイルに S3 Glacier Deep Archive を使用するように、S3 ファイルゲートウェイを構成します。
- D. Amazon S3 ファイルゲートウェイをデプロイします。メタデータファイルとイメージファイルに Amazon S3 標準 - 低頻度アクセス (S3 標準 - IA) を使用するように S3 ファイルゲートウェイを設定します。

<details>
<summary>答え</summary>
D

- Amazon S3 ファイルゲートウェイ をオンプレミスと AWS 側の両方にデプロイすることで、どちらの環境からでも SMB プロトコルで同一データセットへ透過的にアクセスできます。
- ゲートウェイは書き込み後にローカルキャッシュへ即時反映し、変更を非同期で Amazon S3 にアップロードするため、災害時でも 5 分以内にデータ取得が可能です。
</details>

### ✅ 30問目

世界中にオフィスを持つある企業は、1 つの AWS リージョンに 1 Gbps の AWS Direct Connect 接続を使用して接続しています。この接続は、企業のオンプレミスネットワークが AWS クラウドサービスとやり取りするために使用されます。接続は、1 つの Virtual Private Cloud (VPC) に接続する 1 つのプライベート仮想インターフェースで構成されます。

ソリューションアーキテクトは、同じリージョン内に冗長な AWS Direct Connect 接続を追加できるソリューションを構築する必要があります。さらに、ビジネスが発展してリージョンが増えた場合、同じペアの AWS Direct Connect 接続を使用して他のリージョンにもアクセスできるソリューションでなければなりません。

これらの基準を満たすソリューションを選択してください。
AWS Direct Connect ゲートウェイをプロビジョニングします。既存の接続から既存のプライベート仮想インターフェースを削除します。2 つ目の AWS Direct Connect 接続を作成します。各接続に新しいプライベート仮想インターフェースを作成し、両方のプライベート

- A. 仮想インターフェースを AWS Direct Connect ゲートウェイに接続します。AWS Direct Connect ゲートウェイを 1 つの VPC に接続します。
- B. 既存のプライベート仮想インターフェースを保持します。2 つ目の AWS Direct Connect 接続を作成します。新しい接続で新しいプライベート仮想インターフェースを作成し、新しいプライベート仮想インターフェースを 1 つの VPC に接続します。
- C. 既存のプライベート仮想インターフェースを保持します。2 つ目の AWS Direct Connect 接続を作成します。新しい接続で新しいパブリック仮想インターフェースを作成し、新しいパブリック仮想インターフェースを 1 つの VPC に接続します。
- D. AWS Transit Gateway をプロビジョニングします。既存の接続から、既存のプライベート仮想インターフェースを削除します。2 つ目の AWS Direct Connect 接続を作成します。接続ごとに新しいプライベート仮想インターフェースを作成し、両方のプライベート仮想インターフェースを AWS Transit Gateway に接続します。AWS Transit Gateway を 1 つの VPC に関連付けます。

<details>
<summary>答え</summary>
A

- Dと答えてしまった
</details>

### 31問目

ある企業では、小売店の注文用ウェブアプリケーションをリファクタリングしたいと考えています。現在、ウェブホスティング、データベース API サービス、ビジネスロジック用に、負荷分散された Amazon EC2 インスタンスフリートを使用しています。同社は、運用コストを最小限に抑えながら、失敗した注文を保持するメカニズムを備えた、分離されたスケーラブルなアーキテクチャを作成する必要があります。

これらの要件を満たすソリューションを選択してください。

- A. ウェブホスティングに Amazon S3 を使用し、データベース API サービスに Amazon API Gateway を使用します。注文のキューイングに Amazon Simple Queue Service (Amazon SQS) を使用します。ビジネスロジックに Amazon Elastic Container Service (Amazon ECS) を使用し、失敗した注文を保持するために Amazon SQS のロングポーリングを使用します。
- B. ウェブホスティングに AWS Elastic Beanstalk を使用し、データベース API サービスには Amazon API Gateway を使用します。注文のキューイングに Amazon MQ を使用します。ビジネスロジックに AWS Step Functions を使用し、失敗した注文を保持するために、Amazon S3 Glacier Deep Archive を使用します。
- C. ウェブホスティングに Amazon S3 を使用し、データベース API サービスに AWS AppSync を使用します。注文のキューイングに Amazon Simple Queue Service (Amazon SQS) を使用します。ビジネスロジックに AWS Lambda を使用し、失敗した注文を保持するために Amazon SQS のデッドレターキューを使用します。

<details>
<summary>答え</summary>
C

- Aと答えてしまった

</details>

### 32問目

ある会社が、オンプレミス環境で 3 層のウェブアプリケーションをホストしています。最近のトラフィックの急増によりダウンタイムが発生し、経済的にも大きな影響が出たため、会社の経営陣はアプリケーションを AWS に移行するように命じました。アプリケーションは .NET で記述されており、MySQL データベースに依存しています。ソリューションアーキテクトは、毎日 20 万人のユーザーの需要を満たすために、スケーラブルで可用性の高いソリューションを設計する必要があります。

ソリューションアーキテクトが適切なソリューションを設計するために実行する必要がある手順はどれですか。

- A. AWS Elastic Beanstalk を使用して、ウェブサーバー環境と Amazon RDS for MySQL DB インスタンスのマルチ AZ 配置を備えた新しいアプリケーションを作成します。環境は、複数のアベイラビリティーゾーンの Amazon EC2 Auto Scaling グループの前で Network Load Balancer (NLB) を起動する必要があります。Amazon Route 53 エイリアスレコードを使用して、会社のドメインから NLB にトラフィックをルーティングします。
- B. AWS CloudFormation を使用して、3 つのアベイラビリティーゾーンにまたがる Amazon EC2 Auto Scaling グループの前に Application Load Balancer (ALB) を含むスタックを起動します。スタックは、Retain 削除ポリシーを持つ Amazon Aurora MySQL DB クラスターのマルチ AZ 配置で起動する必要があります。Amazon Route 53 エイリアスレコードを使用して、会社のドメインから ALB にトラフィックをルーティングします。
- C. AWS Elastic Beanstalk を使用して、各リージョンに Application Load Balancer (ALB) を備えた 2 つの別々のリージョンにまたがる Auto Scaling を使用したウェブサーバー環境を作成します。クロスリージョンリードレプリカを使用して、Amazon Aurora MySQL DB クラスターのマルチ AZ 配置を作成します。Amazon Route 53 を地理的近接性ルーティングポリシーとともに使用して、2 つのリージョン間でトラフィックをルーティングします。
- D. AWS CloudFormation を使用して、3 つのアベイラビリティーゾーンにまたがるスポットインスタンスの Amazon ECS クラスターの前に Application Load Balancer (ALB) を含むスタックを起動します。スタックは、 Snapshot 削除ポリシーを持つ Amazon RDS MySQL DB インスタンスを起動する必要があります。Amazon Route 53 エイリアスレコードを使用して、会社のドメインから ALB にトラフィックをルーティングします。

<details>
<summary>答え</summary>
B

- CloudFormationは要件にないからダメ！と即ギリしたらダメ
- AはNLBを使うのがおかしい
- Cは要件を超えすぎている

</details>

### 33問目

レンタカー会社は、モバイルアプリにデータを提供するために、サーバーレスの REST API を構築しました。このアプリは、リージョナルなエンドポイントを持つ Amazon API Gateway、AWS Lambda 関数、Amazon Aurora MySQL Serverless DB クラスターで構成されています。同社は最近、この API をパートナー企業のモバイルアプリに公開しました。その結果、リクエスト数が大幅に増加し、データベースのメモリエラーが散発的に発生しました。

API のトラフィックを分析したところ、クライアントが短時間に同じクエリに対して複数の HTTP GET リクエストを行っていることが分かりました。トラフィックは営業時間中に集中しており、休日やその他のイベントの前後に急増します。

このソリューションに関連するコストの増加を最小限に抑えながら、追加の使用量をサポートする能力を向上させる必要があります。

これらの要件を満たす戦略を選択してください。

- A. API Gateway リージョナルなエンドポイントをエッジ最適化エンドポイントに変換します。本番ステージでキャッシュを有効にします。
- B. Amazon ElastiCache for Redis キャッシュを実装して、データベース呼び出しの結果を保存します。キャッシュを使用するように Lambda 関数を変更します。
- C. Aurora Serverless DB クラスターの構成を変更して、使用可能なメモリーの最大量を増やします。
- D. API Gateway の本番ステージでスロットリングを有効にします。レートとバーストの値を設定して、着信コールを制限します。

<details>
<summary>答え</summary>
A
</details>

### ✅ 34問目

AWS Organizations は、企業が複数の AWS アカウントを管理できるようにします。この組織は、ルート OU の下に Research と DataOps という 2 つの OU があります。規制上の制限のため、企業はすべてのリソースを ap-northeast-1 リージョン内にデプロイする必要があります。さらに、組織は、DataOpsOU にデプロイされた EC2 インスタンスに指定されたインスタンスタイプのセットを使用する必要があります。

ソリューションアーキテクトは、これらの制約に準拠するソリューションを実装する責任があります。ソリューションの運用効率は最大化し、継続的なメンテナンスは最小限に抑える必要があります。

これらの基準を満たすアクションの組み合わせを選択してください。 (2 つ選択)

- A. DataOps OU の下で 1 つのアカウントに IAM ロールを作成します。特定のインスタンスタイプへのアクセスを制限するために、ロールのインラインポリシーで ec2:InstanceType 条件キーを使用します。
- B. ルート OU の下にあるすべてのアカウントで IAM ユーザーを作成します。各ユーザーのインラインポリシーで aws:RequestedRegion 条件キーを使用し、ap-northeast-1 以外のすべての AWS リージョンへのアクセスを制限します。
- C. SCP を作成します。aws:RequestedRegion 条件キーを使用して、ap-northeast-1 以外のすべての AWS リージョンにアクセスを制限します。SCP をルート OU に適用します。
- D. SCP を作成します。ec2:Region 条件キーを使用して、ap-northeast-1 以外のすべての AWS リージョンにアクセスを制限します。ルート OU、DataOps OU、および Research OU に SCP を適用します。
- E. SCP を作成します。ec2:InstanceType 条件キーを使用して、特定のインスタンスタイプにアクセスを制限します。SCP を DataOps OU に適用します。

<details>
<summary>答え</summary>
C,E
</details>

### ✅ 35問目

ある企業は、AWS CloudFormation を使用して、AWS メンバーアカウントに新しいインフラストラクチャをすべて作成しました。リソースはほとんど変更されず、予想される負荷に対して適切なサイズが設定されています。毎月の AWS の請求額は一定です。

開発者がテスト用に新しいリソースを作成し、テストの完了時にリソースを削除するのを忘れることがあります。これらのテストのほとんどは、リソースが不要になるまで数日間続きます。

同社は、未使用のリソースを見つけるプロセスを自動化したいと考えています。ソリューションアーキテクトは、AWS の請求額のコストが増加しているかどうかを判断するソリューションを設計する必要があります。このソリューションは、コスト増加の原因となるリソースの特定を支援し、会社の運用チームに自動的に通知する必要があります。

これらの要件を満たすソリューションを選択してください。

- A. 請求アラートを有効にします。AWS Cost Explorer を使用して、過去 1 ヶ月のコストを決定します。見積もり料金合計の Amazon CloudWatch アラームを作成します。Cost Explorer が決定したコストよりも高いコストしきい値を指定します。アラームしきい値を超えた場合に、運用チームに警告する通知を追加します。

- B. 請求アラートを有効にします。AWS Cost Explorer を使用して、過去 3 ヶ月の平均月額コストを決定します。見積もり料金合計の Amazon CloudWatch アラームを作成します。Cost Explorer が決定したコストよりも高いコストしきい値を指定します。アラームしきい値を超えた場合に、運用チームに警告する通知を追加します。

- C. AWS Cost Anomaly Detection を使用して、Linked Account のモニタータイプを持つコストモニターを作成します。運用チームに毎日の AWS コストサマリーを送信するサブスクリプションを作成します。コスト差異のしきい値を指定します。

- D. AWS コスト異常検出を使用して、モニタータイプが AWS サービスのコストモニターを作成します。毎日の AWS コストの概要を運用チームに送信するサブスクリプションを作成します。コスト差異のしきい値を指定します。

<details>
<summary>答え</summary>
D
</details>

### 36問目

ある企業は、AWS Organizations を使用して AWS アカウントを管理しています。ソリューションアーキテクトは、管理者ロールにのみ IAM アクションの使用を許可するソリューションを設計する必要があります。しかし、ソリューションアーキテクトは、会社全体のすべての AWS アカウントにアクセスできるわけではありません。

運用上のオーバーヘッドが最も少なく、これらの要件を満たすソリューションを選択してください。

- A. すべての AWS アカウントに適用される SCP を作成し、管理者ロールにのみ IAM アクションを許可します。SCP をルート OU に適用します。
- B. IAM アクションに関連するイベントごとに AWS Lambda 関数を呼び出すように AWS CloudTrail を設定します。アクションを呼び出したユーザーが管理者でない場合、アクションを拒否するように関数を構成します。
- C. すべての AWS アカウントに適用される SCP を作成し、管理者ロールを持つユーザーを除くすべてのユーザーの IAM アクションを拒否します。SCP をルート OU に適用します。
- D. IAM アクションを許可する IAM アクセス許可の境界を設定します。アクセス許可の境界をすべての AWS アカウントのすべての管理者ロールにアタッチします。

<details>
<summary>答え</summary>
C
</details>

### 37問目

ある企業が、世界中のお客様にサービスを提供する静的コンテンツ配信プラットフォームを運営しています。お客様は、自分の AWS アカウントからコンテンツを消費します。

同社は、Amazon S3 バケットからコンテンツを提供します。同社は、S3 ファイルゲートウェイを使用して、オンプレミス環境から S3 バケットにコンテンツをアップロードします。

同社は、お客様に地理的に最も近い AWS リージョンからコンテンツを提供することで、プラットフォームのパフォーマンスと信頼性を向上させたいと考えています。同社は、オンプレミスのデータを、最小限のレイテンシーで、パブリックインターネットに公開することなく、Amazon S3 にルーティングする必要があります。

これらの要件を満たし、運用オーバーヘッドが最も少ない手順の組み合わせを選択してください。(2 つ選択)

- A. S3 マルチリージョンアクセスポイントを実装します。
- B. S3 クロスリージョンレプリケーション (CRR) を使用して、異なるリージョンにコンテンツをコピーします。
- C. リージョンへのクライアントのルーティングを追跡する AWS Lambda 関数を作成します。
- D. AWS Site-to-Site VPN 接続を使用して、マルチリージョンアクセスポイントに接続します。
- E. AWS PrivateLink と AWS Direct Connect を使用して、マルチリージョンアクセスポイントに接続します。

<details>
<summary>答え</summary>
A,E

- 「Amazon S3 クロスリージョンレプリケーション (CRR)」 は、地理的に最も近いリージョンからのコンテンツ提供を目的としないため間違いです。

</details>


### ✅ 38問目

ある企業は、Amazon Elastic File System (Amazon EFS) ファイルシステムにドキュメントを保存し、管理しています。ファイルシステムは、AWS Key Management Service (AWS KMS) キーで暗号化されています。ファイルシステムは、独自のソフトウェアを実行する Amazon EC2 インスタンスにマウントされています。

同社は、ファイルシステムの自動バックアップを有効にしています。自動バックアップは、AWS Backup のデフォルトのバックアッププランを使用しています。

ソリューションアーキテクトは、削除されたドキュメントを 100 分の RPO 内で回復できるようにする必要があります。

これらの要件を満たすソリューションを選択してください。

- A. 新しい IAM ロールを作成します。新しいバックアッププランを作成します。新しい IAM ロールを使用してバックアップを作成します。KMS キーポリシーを更新して、新しい IAM ロールがキーを使用できるようにします。ファイルシステムに 1 時間ごとのバックアップスケジュールを実装します。
- B. 新しいバックアッププランを作成します。KMS キーポリシーを更新して、AWSServiceRoleForBackup IAM ロールがキーを使用できるようにします。カスタム cron 式を実装して、ファイルシステムのバックアップを 30 分ごとに実行します。
- C. 新しい IAM ロールを作成します。既存のバックアッププランを使用します。KMS キーポリシーを更新して、新しい IAM ロールがキーを使用できるようにします。ポイントインタイムリカバリ (PITR) のために継続的バックアップを有効にします。
- D. 既存のバックアッププランを使用します。AWSServiceRoleForBackup IAM ロールがキーを使用できるように、KMS キーポリシーを更新します。ファイルシステムのクロスリージョンレプリケーションを有効にします。

<details>
<summary>答え</summary>
A
</details>

### ✅ 39問目

ある会社が、サードパーティーのウェブアプリケーションを AWS にデプロイしています。アプリケーションは Docker イメージとしてパッケージ化されています。同社は、Amazon Elastic Container Service (Amazon ECS) の AWS Fargate サービスとして Docker イメージをデプロイしました。Application Load Balancer (ALB) がアプリケーションにトラフィックを転送します。

同社は、インターネットからアプリケーションにアクセスする能力を、特定のユーザーリストにのみ与える必要があります。同社はアプリケーションを変更することはできず、アプリケーションを ID プロバイダーと統合することもできません。すべてのユーザーは、多要素認証 (MFA) によって認証される必要があります。

これらの要件を満たすソリューションを選択してください。

- A. Amazon Cognito でユーザープールを作成します。アプリケーション用にプールを構成します。必要なユーザーをプールに追加します。MFA を要求するようにプールを設定します。ALB でリスナールールを構成して、Amazon Cognito でホストされる UI を介した認証を要求します。
- B. AWS Identity and Access Management (IAM) でユーザーを構成します。ユーザーに MFA の使用を要求するために、Fargate サービスにリソースポリシーをアタッチします。ALB のリスナールールを設定して、IAM を介して認証を要求します。
- C. AWS Identity and Access Management (IAM) でユーザーを構成します。AWS IAM Identity Center (AWS Single Sign-On) を有効にします。ALB のリソース保護を設定します。ユーザーに MFA の使用を要求するリソース保護ルールを作成します。
- D. AWS Amplify にユーザープールを作成します。アプリケーション用にプールを構成します。必要なユーザーをプールに追加します。MFA を要求するようにプールを設定します。ALB のリスナールールを設定して、Amplify ホスト UI を介して認証を要求します。

<details>
<summary>答え</summary>
A
</details>

### 40問目

ある企業は、オンプレミスのデータベース群を Amazon RDS に移行する必要があります。同社は現在、Microsoft SQL Server、MySQL、Oracle データベースを混在して使用しています。一部のデータベースには、カスタムスキーマとストアドプロシージャがあります。

移行のために企業が実行する必要がある手順の組み合わせを選択してください。(2 つ選択)

- A. Migration Evaluator Quick Insights を使用してソースデータベースを分析し、移行が必要なストアドプロシージャを特定します。
- B. AWS Application Migration Service を使用してソースデータベースを分析し、移行が必要なストアドプロシージャを特定します。
- C. AWS Schema Conversion Tool (AWS SCT) を使用して、ソースデータベースを分析し、必要な変更を確認します。
- D. AWS Database Migration Service (AWS DMS) を使用して、ソースデータベースを Amazon RDS に移行します。
- E. AWS DataSync を使用して、ソースデータベースから Amazon RDS にデータを移行します。

<details>
<summary>答え</summary>
C,D

- この問題はもう覚えとく
- AWS Application Migration Serviceはアプリケーションの話なので、ストアドプロシージャは関係ない

</details>

### 41問目

ソリューションアーキテクトが、AWS Import/Export の Amazon EC2 VM Import 機能を使用して、オンプレミス環境から VM をインポートしています。ソリューションアーキテクトは AMI を作成し、その AMI に基づく Amazon EC2 インスタンスをプロビジョニングしました。EC2 インスタンスは、VPC のパブリックサブネット内で実行され、パブリック IP アドレスが割り当てられています。

EC2 インスタンスは、AWS Systems Manager コンソールでマネージドインスタンスとして表示されません。

この問題をトラブルシューティングするために取るべき手順の組み合わせを選択してください。 (2 つ選択)
- A. Systems Manager エージェントがインスタンスにインストールされ、実行されていることを確認します。
- B. インスタンスに Systems Manager の適切な IAM ロールが割り当てられていることを確認します。
- C. VPC に VPC エンドポイントが存在することを確認します。
- D. AWS Application Discovery Agent が設定されていることを確認します。
- E. Systems Manager のサービスにリンクされたロールが正しく設定されていることを確認します。

<details>
<summary>答え</summary>
A,B

- SSM Agent がインストールされていること
- Amazon Linux 2 / AL2023 / Ubuntu / Windows などは、最近の AMI では最初から入っていることが多い

</details>

### 42問目

ある企業は、サードパーティーのデータサプライヤから更新情報を受け取るために、Amazon S3 バケットで AWS Transfer Family SFTP 対応サーバーを使用する必要があります。データは Pretty Good Privacy (PGP) 暗号化で暗号化されています。企業がデータを受け取った後、自動的にデータを復号化するソリューションが必要です。

ソリューションアーキテクトは、Transfer Family マネージドワークフローを使用します。同社は、AWS Secrets Manager と S3 バケットへのアクセスを許可する IAM ポリシーを使用して、IAM サービスロールを作成しました。ロールの信頼関係は、transfer.amazonaws.com サービスがロールを引き受けることを許可しています。

自動復号化のソリューションを完成させるための最適な方法を選択してください。

- A. PGP 公開キーを Secrets Manager に保存します。Transfer Family マネージドワークフローに、ファイルを復号化するための名目上のステップを追加します。名目上のステップで PGP 暗号化パラメータを設定します。ワークフローを Transfer Family サーバーに関連付けます。
- B. PGP 秘密鍵を Secrets Manager に保存します。Transfer Family マネージドワークフローに、ファイルを復号化するための例外処理ステップを追加します。例外ハンドラに PGP 暗号化パラメータを設定します。ワークフローを SFTP ユーザーに関連付けます。
- C. PGP 秘密鍵を Secrets Manager に保存します。Transfer Family マネージドワークフローに、ファイルを復号化するための名目上のステップを追加します。名目上のステップで PGP 復号化パラメータを設定します。ワークフローを Transfer Family サーバーに関連付けます。
- D. PGP 公開キーを Secrets Manager に保存します。Transfer Family マネージドワークフローに、ファイルを復号化するための例外処理ステップを追加します。例外ハンドラに PGP 復号化パラメータを設定します。ワークフローを SFTP ユーザーに関連付けます。

<details>
<summary>答え</summary>
C
</details>

### 43問目

ある企業は、老朽化したデスクトップを置き換えるために、Amazon WorkSpaces をシンクライアント端末と組み合わせて使用したいと考えています。従業員は、臨床試験データを扱うアプリケーションにアクセスするためにデスクトップを使用します。企業のセキュリティポリシーでは、アプリケーションへのアクセスは会社の支店のみに制限する必要があります。同社は、今後 6 カ月以内に支店の増設を検討しています。

これらの要件を最も効率的に満たすソリューションを選択してください。

- A. 支店のパブリックアドレスのリストを使用して、IP アクセスコントロールグループルールを作成します。IP アクセスコントロールグループを WorkSpaces ディレクトリに関連付けます。
- B. AWS Firewall Manager を使用して、IPS セットを使用して、支店のロケーションからのパブリックアドレスのリストでウェブ ACL ルールを作成します。ウェブ ACL を WorkSpaces ディレクトリに関連付けます。
- C. AWS Certificate Manager (ACM) を使用して、支店のロケーションにデプロイされたマシンに信頼できるデバイス証明書を発行します。WorkSpaces ディレクトリで制限付きアクセスを有効にします。
- D. 支店のパブリックアドレスへのアクセスを制限するように Windows ファイアウォールが構成されたカスタム WorkSpace イメージを作成します。そのイメージを使用して、WorkSpaces をデプロイします。

<details>
<summary>答え</summary>
A

- WorkSpaces Personal の IP アクセスコントロールグループは、WorkSpaces への入口を IP アドレスで絞るための機能です。

</details>

### ✅ 44問目

ソリューションアーキテクトは、カスタムドメインの下で 2 つの AWS リージョンにまたがってユーザーにサービスを提供するウェブアプリケーションをデプロイしました。このアプリケーションは、Amazon Route 53 のレイテンシーに基づくルーティングを使用します。ソリューションアーキテクトは、各リージョンの別々のアベイラビリティーゾーンにある 1 組のウェブサーバーに加重レコードセットを関連付けました。

ソリューションアーキテクトは災害復旧シナリオを実行します。あるリージョンのすべてのウェブサーバが停止しても、Route 53 はユーザーをもう一方のリージョンに自動的にリダイレクトしません。

この問題の根本原因として考えられるものを選択してください。(2 つ選択)

- A. ウェブサーバーが停止したリージョンの Weight (重み) が、他のリージョンの Weight (重み) よりも高くなっています。
- B. セカンダリリージョンのウェブサーバーの 1 つが、HTTP ヘルスチェックに合格しませんでした。
- C. レイテンシーリソースレコードセットは、加重リソースレコードセットと組み合わせて使用することはできません。
- D. 「ターゲットの正常性の評価」の設定が、ウェブサーバーが停止したリージョンのドメインに関連付けられているレイテンシーエイリアスリソースレコードセットで無効になっています。
- E. 停止した ウェブサーバーに関連付けられた 1 つ以上の加重リソースレコードセットに対して HTTP ヘルスチェックが設定されていません。

<details>
<summary>答え</summary>
D,E
</details>

### ✅ 45問目

ある企業は、オンプレミスのデータセンターがあり、Kubernetes を使用して AWS で新しいソリューションを開発しています。同社は、開発環境とテスト環境に Amazon Elastic Kubernetes Service (Amazon EKS) クラスターを使用しています。

本番ワークロード用の EKS コントロールプレーンとデータプレーンは、オンプレミスに配置する必要があります。同社は、Kubernetes 管理のために AWS マネージドソリューションを必要としています。

運用オーバーヘッドが最も少ないソリューションを選択してください。

- A. オンプレミスのデータセンターに AWS Outposts サーバーをインストールします。本番ワークロード用に、Outposts サーバー上のローカルクラスター構成を使用して Amazon EKS をデプロイします。
- B. オンプレミスのデータセンターの自社ハードウェアに Amazon EKS Anywhere をインストールします。本番ワークロードを EKS Anywhere クラスターにデプロイします。
- C. オンプレミスのデータセンターに AWS Outposts サーバーをインストールします。本番ワークロード用に、Outposts サーバー上の拡張クラスター構成を使用して Amazon EKS をデプロイします。
- D. オンプレミスのデータセンターに AWS Outposts サーバーをインストールします。Outposts サーバーに Amazon EKS Anywhere をインストールします。本番ワークロードを EKS Anywhere クラスターにデプロイします。


<details>
<summary>答え</summary>
A

- ローカルクラスター
  - コントロールプレーンもワーカーノードも Outposts 上に配置
- 拡張クラスター
  - コントロールプレーンは AWS リージョン、ワーカーノードのみ Outposts 上に配置
- 拡張クラスター構成 は、大規模かつ複雑なワークロードに対応するために設計されており、運用オーバーヘッドが増加します。運用オーバーヘッドが少ないソリューションを求めている場合、この方法は不適切です。拡張クラスター構成は、オンプレミス環境で必要以上のリソースを割り当てることになり、コストと管理の負担が増大します。

</details>

### 46問目

ある企業が、今後 3 年間実行されるプロジェクトのために AWS でアプリケーションをホストしています。このアプリケーションは、Network Load Balancer (NLB) のターゲットグループに登録されている 20 台の Amazon EC2 オンデマンドインスタンスで構成されています。インスタンスは 2 つのアベイラビリティーゾーンに分散されています。アプリケーションはステートレスで、1 日 24 時間、週 7 日間実行されます。

同社は、アプリケーションからの応答が遅いというユーザーからの報告を受けています。パフォーマンスメトリクスによると、通常のアプリケーション使用時のインスタンスの CPU 使用率は 10 % です。しかし、通常数時間続く混雑時には、CPU 使用率が 100 % に増加します。同社は、アプリケーションからの応答が遅いという問題を解決する新しいアーキテクチャが必要です。

これらの要件を最もコスト効率よく満たすソリューションを選択してください。

- A. Auto Scaling グループを作成します。Auto Scaling グループを NLB のターゲットグループにアタッチします。最小キャパシティを 20、希望するキャパシティを 28 に設定します。20 インスタンス分のリザーブドインスタンスを購入します。
- B. リクエストタイプが request のスポットフリートを作成します。TotalTargetCapacity パラメータを 20 に設定します。DefaultTargetCapacityType パラメータを On-Demand に設定します。スポットフリートの作成時に NLB を指定します。
- C. リクエストタイプが maintain のスポットフリートを作成します。TotalTargetCapacity パラメータを 20 に設定します。DefaultTargetCapacityType パラメータを Spot に設定します。NLB を Application Load Balancer に置き換えます。
- D. Auto Scaling グループを作成します。Auto Scaling グループを NLB のターゲットグループにアタッチします。最小キャパシティを 4、最大キャパシティを 28 に設定します。リザーブドインスタンスを 4 台分購入します。

<details>
<summary>答え</summary>
D

- RI は「常時起動しているインスタンス数」に対して買う、と覚えていれば解けた問題

</details>

### 47問目

ある企業には、AWS Key Management Service (AWS KMS) を使用してデータを暗号化および復号化するアプリケーションがあります。このアプリケーションは、AWS リージョンの Amazon S3 バケットにデータを保存します。会社のセキュリティポリシーは、データを S3 バケットに配置する前にデータを暗号化する必要があります。アプリケーションは、S3 バケットからファイルを読み取るときにデータを復号化する必要があります。

会社は、S3 バケットを他のリージョンに複製します。ソリューションアーキテクトは、アプリケーションがリージョン間でデータを暗号化および復号化できるようにソリューションを設計する必要があります。アプリケーションは、各リージョンで同じキーを使用してデータを復号化する必要があります。

これらの要件を満たすソリューションを選択してください。

- A. KMS マルチリージョンのプライマリキーを作成します。KMS マルチリージョンのプライマリキーを使用して、アプリケーションが実行されている追加の各リージョンに KMS マルチリージョンのレプリカキーを作成します。各リージョンで特定のレプリカキーを使用するように、アプリケーションコードを更新します。
- B. アプリケーションを実行する各追加リージョンに、新しいカスタマーマネージドキー (KMS キー) を作成します。各リージョンで特定の KMS キーを使用するように、アプリケーションコードを更新します。
- C. AWS プライベート認証機関を使用して、プライマリリージョンに新しい証明機関 (CA) を作成します。アプリケーションのウェブサイト URL 用の新しいプライベート証明書を CA から発行します。AWS Resource Access Manager (AWS RAM) を使用して、CA を追加のリージョンと共有します。各リージョンで共有された CA 証明書を使用するように、アプリケーションコードを更新します。
- D. AWS Systems Manager Parameter Store を使用して、アプリケーションが実行されている各追加リージョンにパラメータを作成します。プライマリリージョンの KMS キーからキーマテリアルをエクスポートします。各リージョンのパラメータにキーデータを保存します。各リージョンのパラメータからキーデータを使用するようにアプリケーションコードを更新します。

<details>
<summary>答え</summary>
A

- KMSにマルチリージョンのプライマリキーというものがあり、レプリケートすることで他のリージョンでも使えることを知っていたら解けた問題

</details>

### 48問目

あるデータ分析会社は、複数のリザーブドノードで構成される Amazon Redshift クラスターを持っています。従業員のチームが詳細な監査分析レポートを作成しているため、クラスターで予期しない使用量の急増が発生しています。レポートを作成するためのクエリは複雑な読み取りクエリで、CPU に負荷がかかります。

ビジネス要件では、クラスターは常に読み取りと書き込みのクエリに対応できる必要があります。ソリューションアーキテクトは、使用量の急増に対応するソリューションを考案する必要があります。

これらの要件を最もコスト効率よく満たすソリューションを選択してください。

- A. Amazon EMR クラスターをプロビジョニングする 複雑なデータ処理タスクをオフロードします。
- B. AWS Lambda 関数をデプロイして、Amazon CloudWatch のクラスターの CPU メトリクスが 80% に達したときに、従来のサイズ変更オペレーションを使用して Amazon Redshift クラスターに容量を追加します。
- C. AWS Lambda 関数をデプロイし、Amazon CloudWatch のクラスターの CPU メトリクスが 80% に達したときに、伸縮自在なサイズ変更オペレーションを使用して Amazon Redshift クラスターに容量を追加します。
- D. Amazon Redshift クラスターの同時実行スケーリングを有効にします。

<details>
<summary>答え</summary>
D

- これは暗記で覚えとこう

</details>

### 49問目

ある金融サービス会社には、世界中で何千人ものお客様が利用している資産運用商品があります。お客様はアンケートを通じて製品に関するフィードバックを提供しています。同社は、これらのアンケートのデータを分析するために、Amazon EMR 上で動作する新しい分析ソリューションを構築しています。次のユーザーペルソナは、さまざまなアクションを実行するために分析ソリューションにアクセスする必要があります。

・管理者 : チームの要件に基づいて、分析チーム用に EMR クラスターをプロビジョニングします。
・データエンジニア : ETL スクリプトを実行し、データセットを処理、変換、強化します。
・データアナリスト : データに対して SQL や Hive クエリーを実行します。

ソリューションアーキテクトは、すべてのユーザーペルソナが必要なリソースだけに最小権限でアクセスできるようにしなければなりません。ユーザーペルソナは、承認および許可されたアプリケーションのみを起動できる必要があります。また、ソリューションでは、ユーザーペルソナが作成するすべてのリソースのタグ付けを確実に行う必要があります。

これらの要件を満たすソリューションを選択してください。

- A. 各ユーザーペルソナに IAM ロールを作成します。アイデンティティベースのポリシーをアタッチして、ロールを引き受けるユーザーが実行できるアクションを定義します。AWS Config ルールを作成して、非準拠のリソースを確認します。非準拠のリソースを修復するために、管理者に通知するルールを構成します。
- B. EMR クラスターの起動時に Kerberos ベースの認証を設定します。クラスター固有の Kerberos オプションとともに、Kerberos セキュリティ構成を指定します。
- C. AWS Service Catalog を使用して、デプロイに利用可能な Amazon EMR のバージョン、クラスター構成、および各ユーザーペルソナのアクセス許可を制御します。
- D. AWS CloudFormation を使用して EMR クラスターを起動し、クラスターの作成時にリソースベースのポリシーを EMR クラスターにアタッチします。AWS Config ルールを作成して、非準拠のクラスターと非準拠の Amazon S3 バケットを確認します。管理者に非準拠リソースを修復するよう通知するルールを構成します。

<details>
<summary>答え</summary>
C

- 「ペルソナごとに最小限の操作だけを許し、作成されるリソースのタグ付けまで含めて“決められた型以外は使わせない”という要求が出てきたら、IAM や SCP ではなく Service Catalog を疑います。」
- ↑ どう覚えたらいいかをまとめたw

</details>

### 50問目

ある企業が、ワークロード用に Amazon Elastic Kubernetes Service (Amazon EKS) クラスターのデプロイを準備しています。同社は、このクラスターが予測不可能な数のステートレス Pod をサポートすることを期待しています。ワークロードが使用するレプリカの数がワークロードによって自動的にスケーリングされるため、Pod の多くは短期間に作成されます。

ノードの復元力を最大化するソリューションを選択してください。

- A. 別の起動テンプレートを使用して、EKS コントロールプレーンをワークロードノードグループとは別の 2 番目のクラスターにデプロイします。
- B. ワークロードノードグループを更新します。ノードグループの数を少なくし、ノードグループのインスタンスを大きくします。
- C. Kubernetes Cluster Autoscaler を構成して、ワークロードノードグループのコンピューティング能力が不足しないようにします。
- D. アベイラビリティーゾーンに基づく Topology Spread Constraints を使用するようにワークロードを構成します。

<details>
<summary>答え</summary>
D

- Kubernetes Cluster Autoscaler は、予測不可能な数のステートレス Pod に対応するためのスケーリングを提供しますが、このシナリオでは Pod の分散と復元力の向上が主要な要件であるため間違いです。

</details>

### ✅ 51問目

ある企業は複数の AWS アカウントを使用しており、複数の DevOps チームがこれらのアカウントで本番ワークロードと開発ワークロードを実行しています。同社は、DevOps チームが使用しない AWS サービスの一部へのアクセスを一元的に制限したいと考えています。同社は AWS Organizations を使用することを決定し、すべての AWS アカウントを組織に招待することに成功しました。現在使用中のサービスへのアクセスを許可し、いくつかの特定のサービスを拒否したいと考えています。また、複数のアカウントを 1 つのユニットとしてまとめて管理したいと考えています。

これらの要件を満たす最適な手順の組み合わせを選択してください。(3 つ選択)
- A. 拒否リスト戦略を使用します。
- B. AWS IAM のアクセスアドバイザーを確認して、最近使用したサービスを確認します。
- C. AWS Trusted Advisor レポートを確認して、最近使用されたサービスを確認します。
- D. デフォルトの FullAWSAccess SCP を削除します。
- E. 組織単位 (OU) を定義し、OU にメンバーアカウントを配置します。
- F. デフォルトの DenyAWSAccess SCP を削除します。

<details>
<summary>答え</summary>
A,B,E
</details>
